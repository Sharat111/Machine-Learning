{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, auc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing the dataset, set RowNumber as index\n",
    "df = pd.read_csv('bank (1).csv', index_col='RowNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # 10,000 rows, 13 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "RowNumber                                                                     \n",
       "1            15634602  Hargrave          619    France  Female   42       2   \n",
       "2            15647311      Hill          608     Spain  Female   41       1   \n",
       "\n",
       "            Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber                                                       \n",
       "1              0.00              1          1               1   \n",
       "2          83807.86              1          0               1   \n",
       "\n",
       "           EstimatedSalary  Exited  \n",
       "RowNumber                           \n",
       "1                101348.88       1  \n",
       "2                112542.58       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2) #Exited is target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       10000 non-null  int64  \n",
      " 1   Surname          10000 non-null  object \n",
      " 2   CreditScore      10000 non-null  int64  \n",
      " 3   Geography        10000 non-null  object \n",
      " 4   Gender           10000 non-null  object \n",
      " 5   Age              10000 non-null  int64  \n",
      " 6   Tenure           10000 non-null  int64  \n",
      " 7   Balance          10000 non-null  float64\n",
      " 8   NumOfProducts    10000 non-null  int64  \n",
      " 9   HasCrCard        10000 non-null  int64  \n",
      " 10  IsActiveMember   10000 non-null  int64  \n",
      " 11  EstimatedSalary  10000 non-null  float64\n",
      " 12  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surname, Gender and Gepgraphy are Object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at distribution of exited and non-exited customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22d1e9a1e08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Exited\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set has has only around 2000 exited customers and about 8000 Customers are still with Bank- it has bias towards existing customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22d2038fdc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Gender\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bank has bout 4500 female customers and 5500 male customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22d20699888>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Geography\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Customers are from France,  Customers from spain and Genrmany are about half in numbers of France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22d206ec648>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " sns.countplot(x=\"Exited\", hue=\"Gender\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above plot says that female customers have higher propensity to exit the Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22d20769c48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " sns.countplot(x=\"Exited\", hue=\"Geography\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers from Germany have highest propensity to to exit the Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Check Distribution of exited/non-exited Customers as per the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEGCAYAAACNaZVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU1fnA8e+byQaENQlhCZCwy74JgooooOCGVhSwtmi1VC1WpWqtbdVatdIN7U+0UlFBrWgVFRWkLAqoCIR9jYQ9ECAQtkBCtvP740wghIRMkpm5M5n38zzzZHLnzL1vhuGdO+ee8x4xxqCUUiq0hDkdgFJKKf/T5K+UUiFIk79SSoUgTf5KKRWCNPkrpVQICnc6gNLi4uJMUlKS02EopVRQWbly5SFjTLyn7QMu+SclJZGSkuJ0GEopFVREZFdl2mu3j1JKhSBN/kopFYI0+SulVAjS5K+UUiHIo+QvIsNEJFVE0kTk8TIejxKR992PLxORJPf2H4vImhK3IhHp4d0/QSmlVGVVmPxFxAVMBoYDnYAxItKpVLO7gSPGmLbAJGAigDHmXWNMD2NMD+AnwE5jzBpv/gFKKaUqz5Mz/75AmjFmuzEmD5gBjCjVZgQwzX3/Q2CwiEipNmOA96oTrFJKKe/wJPk3B/aU+D3dva3MNsaYAuAYEFuqzSjKSf4iMk5EUkQkJTMz05O4lVJKVYMnyb/0GTxA6UUALthGRPoBp4wxG8o6gDFmijGmjzGmT3y8xxPUlFJKVZEnM3zTgRYlfk8E9pXTJl1EwoH6QFaJx0ejXT5BbcqU87eNG+f/OJRS3uFJ8l8BtBORZGAvNpHfXqrNLGAssBQYCSw07iXCRCQMuBUY6K2glXdoQlcqdFWY/I0xBSIyHpgLuIA3jDEbReQZIMUYMwuYCrwtImnYM/7RJXYxEEg3xmz3fvhKKaWqwqPCbsaY2cDsUtueLHE/F3t2X9ZzvwYuqXqISimlvE1n+CqlVAjS5K+UUiFIk79SSoUgTf5KKRWCNPkrpVQI0uSvlFIhSJO/UkqFIE3+SikVgjT5K6VUCNLkr5RSIUiTv1JKhSBN/kopFYI0+SulVAjS5K+UUiFIk79SSoUgTf5KKRWCNPkrpVQI0uSvlFIhSJO/UkqFIE3+SikVgjT5K6VUCPIo+YvIMBFJFZE0EXm8jMejROR99+PLRCSpxGPdRGSpiGwUkfUiEu298JVSSlVFhclfRFzAZGA40AkYIyKdSjW7GzhijGkLTAImup8bDrwD3GuM6QwMAvK9Fr1SSqkq8eTMvy+QZozZbozJA2YAI0q1GQFMc9//EBgsIgJcDawzxqwFMMYcNsYUeid0pZRSVeVJ8m8O7Cnxe7p7W5ltjDEFwDEgFmgPGBGZKyKrROSxsg4gIuNEJEVEUjIzMyv7NyillKokT5K/lLHNeNgmHLgM+LH7580iMvi8hsZMMcb0Mcb0iY+P9yAkpZRS1eFJ8k8HWpT4PRHYV14bdz9/fSDLvX2RMeaQMeYUMBvoVd2glVJKVU+4B21WAO1EJBnYC4wGbi/VZhYwFlgKjAQWGmOMiMwFHhOR2kAecAX2grCqoaZMOX/buHH+j0MpdWEVJn9jTIGIjAfmAi7gDWPMRhF5BkgxxswCpgJvi0ga9ox/tPu5R0TkH9gPEAPMNsZ84aO/RSmllIc8OfPHGDMb22VTctuTJe7nAreW89x3sMM9lVJKBQid4auUUiFIk79SSoUgj7p9VPAo64Ir6EVXpdS59MxfKaVCkCZ/pZQKQZr8lVIqBGnyV0qpEKTJXymlQpAmf6WUCkGa/JVSKgRp8ldKqRCkyV8ppUKQJn+llApBmvyVUioEafJXSqkQpMlfKaVCkCZ/pZQKQZr8lVIqBGnyV0qpEKSLuajzFBTAnDmwcyc0bGhvR47Yn0qpmkGTvzojOxteeAFefRV27z73sYgIuP56GDoUXC5n4lNKeY9H3T4iMkxEUkUkTUQeL+PxKBF53/34MhFJcm9PEpEcEVnjvv3Lu+Erb9m3D/70J/jtb6FtW5g5Ew4cgNRU+PZb6NIFPv4Ynn0WduxwOlqlVHVVeOYvIi5gMjAUSAdWiMgsY8ymEs3uBo4YY9qKyGhgIjDK/dg2Y0wPL8etvGjnTvjnP+0Z/fLlcPHFZx9r3Bjat4d774W1a+G99+DFF+H3v3csXKWUF3hy5t8XSDPGbDfG5AEzgBGl2owAprnvfwgMFhHxXpjKV374ASZNguhoePTRcxN/ad272zZhYfDaa5Cb6784lVLe5Unybw7sKfF7untbmW2MMQXAMSDW/ViyiKwWkUUicnlZBxCRcSKSIiIpmZmZlfoDVNUdO2b79xs0sEm9ceOKnxMbC3feCXv2wCOP+DxEpZSPeJL8yzqDNx62yQBaGmN6AhOA/4hIvfMaGjPFGNPHGNMnPj7eg5BUdRkD774LeXlw332VG8nTvbu98Dt5Mnzwge9iVEr5jifJPx1oUeL3RGBfeW1EJByoD2QZY04bYw4DGGNWAtuA9tUNWlXfe+/ZPvwRI6BJk8o//+aboV8/GD8eTp3yfnxKKd/yJPmvANqJSLKIRAKjgVml2swCxrrvjwQWGmOMiMS7LxgjIq2BdsB274Suqmr/fnjgAUhOhiFDqrYPlwv+8hfIzIQ33/RufEop36sw+bv78McDc4HNwAfGmI0i8oyI3OhuNhWIFZE0bPdO8XDQgcA6EVmLvRB8rzEmy9t/hKqcX/0KTp60ffdh1Zjjffnl0L8//O1vdmKYUip4eDTJyxgzG5hdatuTJe7nAreW8byPgI+qGaPyorVr4b//haeeqlp3T0ki8Pjjtuvogw/g9tu9E6NSyve0tk+IeeEFiImBBx/0zv6uvx46dbL7NaWHASilApYm/xCydas9Q7//fu/V6QkLg9/8Btavt/WAlFLBQZN/CJk40dboefhh7+53zBho0cJeAFZKBQdN/iFizx6YPh3uuaf6ff2lRUTY8g+LFsHhw97dt1LKNzT5h4i//932yT/6qG/2P3q0/blihW/2r5TyLk3+IeD0aZg61SboVq18c4zWre2kr5QU3+xfKeVdmvxDwKpVtlb/uHG+Pc6YMbZ7af9+3x5HKVV9mvxDwHffQZs2cNllvj3ObbfZsf/Ll/v2OEqp6tPkX8NlZtqyzXfeaROzLzVtamv/r1ihY/6VCnSa/Gu4pUtt0h87tuK23nDxxXDwoO3+UUoFLk3+NVhREXz/PXTsaMfh+0OvXmdXBFNKBS5N/jVYaqoddz9ggP+OWaeOLfewcqV2/SgVyDT512BLl0KtWtDDzyso9+gBWVl2UXilVGDS5F9D5eXBmjXQuzdERvr32J07258bNvj3uEopz2nyr6E2bbKTu3r39v+xGzaExERN/koFMk3+NdTq1VC7NnTo4Mzxu3SBtDTIyXHm+EqpC9PkXwMVFMC6dXahdZfLmRi6drWjjTZvdub4SqkL0+RfA/3wg11UvWdP52JITrbfPLTrR6nApMm/Blq1CqKi7JBLp7hc9vjr1+uQT6UCkSb/GqaoyI7y6drV1tl3UpcucPy4jUcpFVg8WsBdRIYBLwEu4HVjzAulHo8CpgO9gcPAKGPMzhKPtwQ2AU8bY/7mndBVWbZtgxMnnO3yKVY85HP2bB/EM2VK+Y/5unypUjVAhWf+IuICJgPDgU7AGBEp3aFwN3DEGNMWmARMLPX4JEBXePWDVasgPNyedTutXj1ISoIvvnA6EqVUaZ6c+fcF0owx2wFEZAYwAnsmX2wE8LT7/ofAyyIixhgjIjcB24GTXotalckY28XSqRNERzsdjdW5s13Y/dgxqF+/jAYXOoMfO9YOF1q3ztaqiI+3q8ZcdJHP4lUqVHiS/JsDJWs0pgP9ymtjjCkQkWNArIjkAL8BhgKPVD9cdSGbNtmyCtdd53QkZ3XsaM/8Fy2CG2/08Enp6bB4MTzyiO3DAggLsxc0inXqZHeYnOz1mJUKBZ4k/7KqwJcev1Femz8Ck4wx2XKBYvIiMg4YB9CyZUsPQlJlmePuWCvuaw8Eycm2vtCCBR4k/x07YOZMO1Y1PNwuDXbdddCtG7RrB0ePwvbt8NVX8Oyz8MILdjLD2LG2opxSymOeJP90oGRB4ESgdMmu4jbpIhIO1AeysN8QRorIX4AGQJGI5BpjXi75ZGPMFGAKQJ8+fXRgYBXNmQPNm9vyCoEiIsKuILZw4QUaZWbCxx/bUqB168LIkbYU6cMPn9suLs7e+va1nyhffQWffw5//Ss88ADExvr0b1GqJvEk+a8A2olIMrAXGA3cXqrNLGAssBQYCSw0xhjg8uIGIvI0kF068SvvOHECliyBK690OpLzDR4Mjz8OBw5AQkKJBwoLYf58+OQTu+LMddfB1VefvWBxoesB0dEwfLhdn/LVV+23gAceAP3mqJRHKkz+7j788cBc7FDPN4wxG0XkGSDFGDMLmAq8LSJp2DP+0b4MWp1vwQLIzw+MUT6lDT42E/gRC3+3gDF9t9mNmZnw5pt2bGqXLvDjH0OjRpXfefv28Oij8M9/wqRJ8MQTXo1dqZrKo3H+xpjZwOxS254scT8XuLWCfTxdhfiUh+bMsT0mbds6Hcn5erY8TIPap1mwpblN/hs3wuuvk18A2/rfxcHkfrDBXhMaOLAKB2jWDH79a/jzn2HyZPsNoF497/4RStUwHiV/FdiMscl/yBDnCrldiCvMMKj9PhZsbgpz59r+/ebNWd37PnJj4rxzkPh4O7nrpZfg8svhvvvsCKHSdAKYUoAm/6BRVvd3cR7btMkumP6HPwRuHZ3BHfZyxZqX7Gie3r1h7Fhyl0V59yAdO8Jtt8GMGfZCsMdjS5UKPVrbpwYoHuI5fLizcZTLGEan/5WHeIkNHW+Bn//cVp7zhUGD4JJL7Iuyc6dvjqFUDaDJvwaYM8cWcktMdDqScnz+OXHfzuKtyHt4LubPdmSPr4jAqFG2z3/aNHsVXCl1Hk3+Qe7kSTvEc9gwpyMpW9vv37FdMAMGsKD7IyxMbe77rqnate3ooX37zn4tUkqdQ5N/kFuyxJ7cDhnidCTnq79/C5f/5147BOmOO7jyov0cPFGbzRkNfH/wbt2gXz+b/Pfsqbi9UiFGk3+Qmz8fIiPtLNpA4srLYciU2yiIqAX33AMuF4Pa24nhX//QzD9BjBplyz68917gXglXyiGa/IPcggVw6aW2pyOQDHj/QWL3rueru94+U28iOe4ELRpm8/UPTf0TRJ06MGKEnUi2apV/jqlUkNChnkEsM9OWcH72We/t80IVFTzVbMtCLvrm36y5+jHSuwzDXbYJEbiywz7mbGzhvxPxSy+1NYBmzrRdQUopQJN/UCsuluZUf39ZHxRhBXlcOmM8x+Nas/KGp897fFD7fUz/vj2bMhoCR3weI2FhtlDcSy/ZF+yXv/T9MZUKAtrtE8QWLLALpPTu7XQkZ3VZ+E8aZmzmu1EvURhZ67zHB3XIAODrVD91/YCt/d+1q11PMjPTf8dVKoBp8g9i8+fbOU3hAfL9rfaRvfT+/Gl2db2e3d2uL7NNctwJWsWe4Ct/XfQtdsstcPq0rf6plNLkH6wyM+3aJ4E0xPOSjx5FCgv4btRLF2w3qP0+Fv3QlCJ/DsBp2tQO/XzlFcjI8OOBlQpMmvyD1JYt9ufgwc7GUSx2zxrarniP9UN/zYn41hdsO6h9Boeya7HzmJ9XnbnuOjspYuJE/x5XqQAUIB0GqrI2b7aVjDt2dDoSq/dnT3G6Vn3WDq14qebi8f6rDzSjdQM/XPQt1rixPfufPNm+eA1KTTbTip8qhGjyD0JFRZCaCjff7NsyOZ6K37mCpLWz2NntRlqv/O/5DUrV6E+KyyYp9jhrDjTjlg4b/RNksWuvhe+/hy+/hNG65pAKXZr8g9DevZCdXbn+fm+M3y9P71lPkh9Vh70dPe+DGtQ+g5krW1FkIMyfH2Dx8XZ94CVL4JprAmvBY6X8SPv8g1Bqqv0ZCOv1JqR9S8uNX7LnomsojIj2+HlXddzH8bxoth+twtKN1TV8uP36NG+e/4+tVIDQ5B+Etmyx3dctWjgdCfT+/I+cqtuYfR0GVep5V3aw/f6r9jf3QVQViIuDvn3t2X92tv+Pr1QA0OQfZAoLYevWwLjQG7drJYmb57F+6K8pCq/c4iyJDU/Sou5RVh3w83j/YsOG2ZE/xdOklQoxmvyDzO7dkJsLHTo4HQl0nzuRvOh6bBr4iyo9v2eTfaw90JSCIgeuWjdtCj162Lo/OTn+P75SDvMo+YvIMBFJFZE0EXm8jMejROR99+PLRCTJvb2viKxx39aKyM3eDT/0FI/vb9/e2TjqHdhK8qqP2DjofvJr1a/SPnol7OVUQSQ/ZHlpEffKGjYMTp2CxYudOb5SDqow+YuIC5gMDAc6AWNEpFOpZncDR4wxbYFJQPEsmg1AH2NMD2AY8JqI6AijakhNhebN7SqFTuo+728UuSLYcNWDVd5HzwQ709aRfn+ApCRb92f+fMjLcyYGpRziyZl/XyDNGLPdGJMHzABGlGozApjmvv8hMFhExBhzyhhT4N4eDeiKGtWQnw9pac53+dQ6lkH7pW/xw4C7yKnfpMr7aRCdS5sGh53r9wc78uf4cfj2W+diUMoBniT/5kDJdfDS3dvKbONO9seAWAAR6SciG4H1wL0lPgzOEJFxIpIiIimZWnWxXDt22A8Apy/2dln4T6SwgLVXVzybtyK9muxjfWYT8goduvzUrh20aQNz5+rZvwopnvyPK+tqXOkz+HLbGGOWGWM6AxcDvxWR8waDG2OmGGP6GGP6xMfHexBSaEpNtTN627VzLobw3Gw6Lf4XO3v+iBPxbaq9v54Je8krDGfToQQvRFcFInbW75Ej8M47zsSglAM8Sf7pQMkR5YnAvvLauPv06wNZJRsYYzYDJ4EuVQ021G3ZAq1aObtkY4elbxF16ijrhkzwyv66N84gTIqc7frp3BlatrTlngsLnYtDKT/yJPmvANqJSLKIRAKjgVml2swCxrrvjwQWGmOM+znhACLSCugA7PRK5CEmN9d2+zjZ3y9FhXSdP4n9rftzsE1/r+wzJjKfDo0OOXfRF+zZ//DhdgLFf8uoTaRUDVRh8nf30Y8H5gKbgQ+MMRtF5BkRudHdbCoQKyJpwASgeDjoZcBaEVkDfAzcb4w55O0/IhRs3WpPSi+6yLkYWq2dRb1D21nvpbP+Yr0S9rLpUGNO5Ud4db+V0qOHHfnz3HO29INSNZxHV9mMMbONMe2NMW2MMc+5tz1pjJnlvp9rjLnVGNPWGNPXGLPdvf1tY0xnY0wPY0wvY8wnvvtTarbNmyEiAtq2dS6GbvP+zvG4ZHb29O50jT5N0yk0Yax2susnLAz+8AfYsAHef9+5OJTyEx1zHyQ2b7aJP8Khk+OLZ/6WJtu+Ja33KDp8M9Wr++4af4Ba4fks25cI7PLqvivlttvg+efhqafg1lsDZ31MpXxAyzsEgYwM2LfP2S6f5lvmUxBRiwNtBnh93xGuInok7GNFhsOV6sLC4E9/sn1s06ZV3F6pIKbJPwgsWGB/OpX862TtJn73KjLaXlapss2V0a/pHvZl1yPtoMNTl2+80Vb8fOYZu+C7UjWUfq8NAvPmQUwMJCaeu92XC7SU1GXh/wGwr8NVPjvGxc3SAZi7MZG2jTf57DgVEoFnn4Wrr7Yv8AMPOBeLUj6kZ/4Bzhib/Dt2tL0S/haRe4KLlkwhs2VvTtfx3cIriXWP0yzmOHM3BcAiBUOGwKBB8Mc/2slfStVAmvwD3ObNts/fqS6fDt++QWTu8Uot0VhVFzfdw8LUZuQVOPy2FIFJk2zif/ppZ2NRykc0+Qe44pUGnUj+UlRIl4Uvsb/NpZyIS/b58fo2Tefk6Qi+3eZQqYeSevSAn/8cJk+GjX5eZF4pP9DkH+Dmz7dDPGNj/X/spDWfUO/QDtYPedgvx+vZZB/hYUXM3RgAXT9g+/7r1oWHHrL9b0rVIHrBN4Dl5cHXX8MddzhwcGPo9r+/cjyuNTt73OT1sf1lqRORz4A2+5m7KZEXfrTc58c7T1lX0K+5xk76uv9+ePVV/8eklI9o8g9g33xj1xcfPhz27/fvsRO2fUfCjmV8M/plTJirWvuqzEJZwzqn88Qnfdl7pDbNG56q1nG94oor7D/EjBm28Fv9qq1aplSg0W6fADZ7NkRGwlW+G2FZrm7z/k5unUb8MOBOvx73xu52hu9n61r59bjlcrngJz+BY8fg8fNWMFUqaOmZfwCbPdueeMbE+Pe49Q5sJWntJ6we9gQFUXX8euxOTY/QJv4Yn65txb1XbPbrscuVnGw/gf/1L6hTp+wFlMeN839cSlWDnvkHqB077DDPa6/1/7G7LphEkSuCjVeO9/uxRWBE910sTG3OiVwHq3yWNmIExMXB22/ril+qRtDkH6DmzLE//Z38o48fpMN3b7G13x3VWp+3OkZ030legYsvNyZW3NhfoqLslfeDB+Gzz5yORqlq026fADV7tl1a1t9LNnZd+BKuglzWXv2Yfw9cwoA2B4itk8una5K4tfeOMi8YDxzo/7i46CK47DI7+aJnT2jd2oEglPIOPfMPQDk5sHChPeuXslZH9pGInGN0+noyO3rewrEmzi0ZFu4yXN9tF19saEl+oR9fAE+MHAkNG8Jbb2n3jwpqmvwD0Ndf2w8Af3f5dFr0KlE5x1g9/Lf+PXAZRnTfxdFTUSzZ2tTpUM5Vq5Yd/XPgAMwqvZqpUsFDu30cVF5VzvXrbY4ZNMh/sbjycug6fxJ7Ol3D4Za9/HfgclzdKZ3oiAI+XduKW5ruczqcc3XqZPud5s+33T9t2jgdkVKVpsk/wBhj+/sHD4Zo35TOL1OHb9+g9omDbG3WhY6L/VQr+gLqRBUwpONePl2bxI+aLPVr95dHbrnFfkq//Tb87ndOR6NUpWnyDzAZGbB9OzzyiP+OGVaQR/f//YVjcW041tjPV5gv4OaeO/l8fStSs+LoGHvI6XDOFR0NP/4xvPyyHZp1ofU1dQ6ACkDa5x9g1qyxP0eM8N8xO3w7lbpZu9nd7Xr/XmGuwM09dhDhKmThrgDtVuna1a769eWXsHev09EoVSkeJX8RGSYiqSKSJiLnzXEXkSgRed/9+DIRSXJvHyoiK0VkvfunA4UKgsvq1dCvHzRr5p/jufJz6Tn7OTLaXsaRJg4uElyGhnXyGNY5nYW72lAUqEU1R42yF2imT4eiIqejUcpjFSZ/EXEBk4HhQCdgjIh0KtXsbuCIMaYtMAmY6N5+CLjBGNMVGAu87a3Aa6KsLNi9G26+2X/H7LhkCjFH95Jy4zMBddZfbMzFaWSeimF9pjMTzioUE2M/AHbuhEWLnI5GKY95cubfF0gzxmw3xuQBM4DSnRIjgGnu+x8Cg0VEjDGrjTHFQzU2AtEiEuWNwGui4i6fm27yz/FceafoOed59rUfREaHK/1z0Eq6odsuolwFLNgZoF0/ABdfbCeAffKJLQCnVBDwJPk3B/aU+D3dva3MNsaYAuAYUHr5kVuA1caY06UPICLjRCRFRFIyMzM9jb3GWbMGmjaFDn6aX9X561eoffyAPesPUDHRBVyauIuvd7emoCjwvpkA9hvTmDFQUAAffuh0NEp5xJPkX9b/uNI9sBdsIyKdsV1BvyjrAMaYKcaYPsaYPvHx8R6EVPNkZ8PWrXb1QH+IPHmEHnOeZ0+nq9nf7nL/HLSKrmqVxrHTtVi1v/Q5RwBJSLALvyxfbivyKRXgPEn+6UDJdfUSgdKzbs60EZFwoD6Q5f49EfgY+KkxZlt1A66p1q+31wv9lfx7zX6WqJyjLLvlr/45YDX0a7aHmIjTLAjUUT/Fhg+H+Hh47z3Iz3c6GqUuyJPkvwJoJyLJIhIJjAZKz2ufhb2gCzASWGiMMSLSAPgC+K0x5ltvBV0TrVljS8a08sMaJnUzt9P5q/8jdcBdZCV28/0BqynSVcRlLXayZE8ypwuqt6qYT0VEwOjRtvTD/PlOR6PUBVWY/N19+OOBucBm4ANjzEYReUZEbnQ3mwrEikgaMAEoHg46HmgL/EFE1rhvjb3+VwS506dh40bo3t33A246Lp7C4Cm3AcLRxh3ouHjKmVsguyZ5KyfzI1m8J8npUC6sSxdb8uGLL+DwYaejUapcHo3zN8bMNsa0N8a0McY85972pDFmlvt+rjHmVmNMW2NMX2PMdvf2Z40xdYwxPUrcDvruzwlO69fbXoJefiipUzdzG413ryS909Xk1W7g+wN6SY+EfTSLOc4X2zo6HUrFbrvNfop/8IHTkShVLp3hGwBWrIB69Xxfu1+KCmmbMoPTteqz56Khvj2Yl4UJXNtmC6sPNCf9RD2nw7mwRo3guutsX96GDU5Ho1SZNPk7LCfH5oc+fSDMx/8aFy1+jbpZu9ne61aKIvxYNc5Lhrf+gTApYvY259Ya8NiQIXYE0Hvv2X9kpQKMJn+HrV1rh4f36ePb49Q6foCLP3mCI006ktnKxwfzkbjap7ik2R7mbOtAQaAt8lJaeLgt/HboEDz/vNPRKHUeTf4OS0mxo3ySk317nH4fPUZ43inSLh4TkGUcPHVdmy1k5dZm9oaWTodSsQ4d4JJLYOJE2LLF6WiUOocmfwedPAmbNvm+y6fpD4to//101g19hJx6AVojx0OXNN9No+hTvP5NEFz4BVv3v04duPdeu1iDUgFCk7+D1qyBwkLfdvm48nIY+PY9HI9LZvW1wb/oSHiYYXjrVL5Y34LdWXWcDqdi9erZM/9Fi2DatIrbK+UnmvwdtGIFxMX5dmJXn8+eov7BNBb/5HUKooIgWXrgxna2fMLLX3VxOBIP3XMPXHopTJhgJ4ApFQB0JS+HHDwIqalw9dXnd8GXt7ZvZcXtTKHrvL+z+bJ72NcxOJZSWLy44jZNYrIZ2WsHU5Z05A/XraJudICXUggLg9dft7U7xo+H//7X6YiU0jN/p7z7rq3l06+fb/YfVpDHFdN/Rk79JkFRv6eyJgxdx7GcKN78rr3ToXimY0d46ilb9XPmTKejUUqTv1OmTYOkJN+t2NVz9rPE7h67iz4AABgsSURBVF3PN7e/GlQzeT3VLzmTAW328+KCrhQGaqnn0h55xJ7933+/XblHKQdp8nfAmjV2fP8ll/hm/3E7U+g553l+uOSn7Op+Y8VPCFIThqxnx6F6fLrGD9XwvCEiAt54w479f/BBp6NRIU77/B0wbRpERtoFoLzNlZ/LoLfGcqpeE74b9ZL3DxBAbuqxk6TY4/xjfjd+1Gun0+GUr/RFnOHD4Z137BKQr77qTEwq5Gny97O8PPv//oYb7P99b+s96ykaZWxi/ZUP0DqlZhcWc4UZHrxqAw//dwBLtjbh8nb7nQ7JM9dea7/6vfsuPPOMXQNAKT/Tbh8/mzPHfuu/807v7zsh7Vu6zfsbGW0v40izIBkGWU3jBm4mod4pfv9pH4yxo4VK3wKOywV33WVr/ujkL+UQTf5+Nm0aNG5sV/zzpvDcbAa9NZbs2FZs73Wrd3cewGpHFvK74atZvLUZC7YE8DKPpTVvDjfeaEf+vPuu09GoEKTdPn6UmQmffw4PPGCv/XlTv5mPUe/Qdj6b8DUN9odWHZlxl2/mr//rzu8/7cPE/nuDp3TR0KG2+2fcOEhPt6WgSxo3zpm4VEjQM38/mjrVLtrys59Vf18lV+Dq//5DdF70Kukdh4Rc4geIiijiD9etYtmOBJbuDYKCb8XCwmz3T1ERvPWW/amUn2jy95PCQvjXv2DQIOjc2Xv7DT99kvZLp3GyflN2dh/hvR0HmTsHpNI67jhT1/WhKJi60OPj7cpfqamwcKHT0agQosnfT2bPhl274Je/9O5+26S8T0TucVL734VxebkvKYhEuAx/vCGFtCNxfLk9SGb9Frv0UujWDT7+GPbtczoaFSI0+fvJK6/Y2bwjvHhyHrt7FQk7l7G7y7VkxwbJRCcfur1vGl3i9vOv1f04fjrK6XA8JwI/+QlER8Obb9rVfZTyMU3+frBtG3z5pb1+560LvRE5x2m3/F1ONGrJni7XemenQS4sDB7u+w0n8qL491ofzKDzpXr14I47YPduOypAKR/zKPmLyDARSRWRNBF5vIzHo0Tkfffjy0Qkyb09VkS+EpFsEXnZu6EHj1dftav6/fznXtqhMbRb/g7h+bmkDrgLE+by0o6DX9uGWfyo/UY+23oRmw8H2eSpnj2hf397prBtm9PRqBquwuQvIi5gMjAc6ASMEZFOpZrdDRwxxrQFJgET3dtzgT8Aj3gt4iBz6pQt53Lzzd4r4tbhuzeJS1/Ljh43caq+jyrDBbG7uqXQMDqHScsvDZ6ib8VGjbJDPt98E7KznY5G1WCenPn3BdKMMduNMXnADKB0z/UIoHiZog+BwSIixpiTxphvsB8CIWPKlLO3u++GI0fs2H5vqJu5nf7vP8jRhA7s7TjYOzutYWIi8xnfeympWY2Zsbmb0+FUTq1advr3oUO2CqhSPuJJ8m8O7Cnxe7p7W5ltjDEFwDEg1tMgRGSciKSISEpmZqanTwt4hYXwv/9BmzZw2WXV358UFXLlmz8FCSO1/50gesmmPFe12saVLbcxde3FpOyMczqcymnfHoYMgddes8PElPIBT2b4lvW9ufRIak/alMsYMwWYAtCnT59gGqV9QcuX27Ltt99+/mpdVdH9y4k02fYtX901HVdeTvV3WIOJwK/7LmHDoQR+/MZVrPrdTOpEBdEomhEjYONGGDPGLgJTugqgzv5V1eTJqWM60KLE74lA6cHIZ9qISDhQHwjp1SqKimwRt8RE6OKFGmsJad/Q57Mn2dZnFFv73VH9HYaAulF5PNH/K7YerM+E//Z3OpzKiYiwU8FPnrS1f7T4m/IyT5L/CqCdiCSLSCQwGphVqs0sYKz7/khgoTGh/W5ds8au1T18ePXP+qOyDzP49TGciE1i8R1TvPM1IkT0apLBY1evZcqSi/jP8jZOh1M5LVrYbwCrVsF33zkdjaphKkz+7j788cBcYDPwgTFmo4g8IyLFy0RNBWJFJA2YAJwZDioiO4F/AHeKSHoZI4VqHGPsWX/jxtCrV/V3NmjaXdQ6foAF98wgv1Y9r8QYSv40YgUD2+3j7ulXBF///9Ch0KEDvP8+HDzodDSqBvGoqqcxZjYwu9S2J0vczwXKrCNsjEmqRnxBae1aO1fnpz+1E4+qo8ecP9Nq3Wd8d9uLHErq450Aa4DK1OmPcBk+/MV8Lv7zzdz06tWkPPExTeoHyTWTsDA7+udPf7KVAR97zK4HoFQ1aUlnL8vPtyXamzY9d43e0iv5eSJ51Uf0/fR3pF08mg1X/cp7QYag+Lq5fHrfXAb8ZQQ3v3o1X/36c6IjCp0OyzONGtnZv1OmwGefwU03OR2RqgE0+XvZlCm2r3/8+OqdoMXtWsmVb/yEA8mXsGjsm9rP7wXdW2Qx7c6vuXXKUIa+MJg/Xj6P8LBzL00NHOhQcBXp3dsWgJszB9q2dToaVQPoQHEvOnYMnn7adtFWZ4RP3UM7uOaVG8mpG8//7v+Ewohor8UY6kb23sHLo7/hm/QkXlg6KLjKP48ebVcAe+MNu/iLUtWgyd+L/vxnOHwYRo6s+ol63cztXP/3Qbjycvhy/Ofk1EvwbpCKX165iXu6L2fezna8tOLS4BlFGRlpx/cXFNgPgvx8pyNSQUy7fbxk+3Z48UVbmbdlFReTqncwjev/cSXheTl8MWEhCduWkrBtqXcDVQDc0XkN2XlRzNjcnfwiFxP6LjmvCyggNWli+/+nToWHH4aXQ7ZeoqomPfP3AmNsxc7ISHj++artI37Hcm7420Bc+bl8PmEhh1v08G6Q6hwicG/PZYztupIvtnXkiUXXcCo/SM6F+vaFX/8aJk/W5K+qLEje7YHt9dftCnxTptgu2crq8O0bXPaf+zhZvxmzH5rHkWZeXOdRlUsEftZtJfG1TzJp+WU8NP8Gvuw+j6Q471bTLGtYarUvLE+cCFu3woMP2gvAw4ZVc4cq1OiZfzXt2WNPwq66Cu65p3LPdeWd4rJ37+OK6XeT0W4gHz+RoonfATe03cJzV8xlz/H6dH1mJP9e0jHwrwO4XLbsQ9eutgz0ypVOR6SCjJ75V4MxcO+9tnrnv/9duYu8jbd/z6A3f0qDg1tZe/WjLL/peYxL/zl8wZMJYf2b7+GN6z7ktS1XMO6dgcxcncTfRi6jc7Mjvg/QrdLfEGJi7Lj/yy+3M4Hnz/fClHIVKjTbVMO//mUr7r74IrRu7dlzXPm59Pr8j3Sf+xdONkxk7eAJHItvS4dv3/BtsKpCTWOymf/QF7y6qBO/+bgfXf54Kzd238nj16zhktYHA2uqRclZg+PGwT/+YT8EHn4Ynn3WubhU0NDkX0UrVsBDD8G113q+UEuTrUsY+PY9NDjwA6kD7uK72ybRZsX7vg1UVUpYmB0KOuribbz8VRf+76vODFh7E8lxx7muy26u7bqHbs0Ps3XdKcJKfRgUn6WfynNx5GQUR3OiOHoqknUHwRVmcEkR9SJP06jWKcCLs4vj4mDCBPsBMGmS/RC45hrv7V/VSBJoxTf79OljUlJSnA7jgg4fthMuwRZcbNTo3MdLl3LotOCfJK/5mOY/fE1unVh+6HcHR5vW+Pp2Qal0N0t2bjj/Wd6Wz9a1YsGW5uS4RwRFugpoUucEkS6bxI0R8iSKQ9nRZ9pcSL3oPJLjjtMh4RjtE47RtXkWhQcyaRZz4pxvGJW6MHz4sB0BlJFhJ508+qjODA8hIrLSGONxATA98/dQcUIvKrL/v/butf+3Sif+0pptWUifL54h6mQW6R2uYmePmygKj/J9wMorYqILGDdwC+MGbiEnz8V32xJIPdCAxWvqsj+7LgXGjpkQoE2LQ8TF5BIXk0uj2qdpUDuP+rXy2LDBUGSEgiIXx09HkZVbi6iGddh+qC6r98Ty0epkCovsfmIiT9M57gA9GmfQI2EfAwoPEe7y8AQtNhZ+8xv45hv7c9ky3r5kMjn1m5zXVNeCUZr8K2nmTNiwwa7OlZRUfrvw0yfp99FjdF70CqfqNmbt0Ec43lhrsgSzWpGFDL5oH4Mv2keXMsbJlXeWXuvwhdvmFYSxYV9D3psfT+rheNZnJvDamn4A/GZRHld22MfQi9K5on0GnZoeuXCl2KgomDED+vSB3/+eUbPns+Km59h0xX2YMK0Gqs7S5F8J8+bZ21VXnf3PW1a1zoS0bxn01ljqHdrO+sEPcSyuDUXhkf4NVvldZcpMlxQZXkSvlofJbnuYG9puASArpxZrDjZlH82Zt7k5n65NAmx3Ud/kg3RqeoTEBidJbHiSerXyCBMIE0OYGJgv0ONRYqffRP3f/ZJLZzxAp69fYd3Vj7C1748pitBvnkr7/D12zz12Rn3v3vZ+WWdfrrxTXPzJ7+m68EVOxCaxaOybZLS/go6Lq1DPWdVoZX1LKG+opzGw/VBdvtvWhKXbG/P99gS2ZNQjp8CTEwrDLXzEk/yJbqzjUEQTFiXfSdz9o2h+bXeSW8uZ6rNlncho91DwqGyfvyZ/D8ycCbfdBm3awK9+ZZdXLa3J1iVcMf1n1D+YxqaB97Lslr+QH10XQJO/qrLyupIWL4aT+RFknqpDTkEExkC37mFnJqcZIDs3giUptTh6OpqMEzE0ObSBm068w1UFcwmnkB9ox2y5npTYa9jb+nKO5tWmyfFU6kbmERNxmpjI01zcLY/4mBwSG54k8eFbqV/fzmkpi35QOEsv+HrZa6/B/fdDq1Zw333nJ/5axzLoN/Nx2n8/neNxyXw2YSEZHa50JlgVUupE5FOn/tEzvxfsPffx2sA1peafbBn4BVMzDzE0+2Nqf/Yhv9zyChGHJpGXFcWK8AEsMZcxt2gIMwsHUEg4lJw4/AzUq2cHOTRpYm/Nm0NiIjRs6LM/U/mInvmXwxi7ct5TT8F119nSKZElvmWH52bT+evJ9JzzHK6C06wbMoHVw39HQXTMefvSM38VaM58o8jLszWCNm3ixMpUYo6kIxjyI2qT2bgTrj492dVsADsLEknvOITt220dq/374UiJyc+1a9trzN27Q7du9meXLvD22+cfW78h+Iae+XvB3r3wi1/AF1/A2LH2a+6bb9rHIk8eofPXk+m6YBLRJ7PY1fU6lt46ieMJ7ZwNWqlKOHt9IRLoDAmd4VoIP51Ng/2pNMzYSGzGJqI+TSGBf9MxNpktl91Dix4j6PZgJxAhJ8f+X9m7164tk59v15k5edLuOSwMEhLsN4PERGjRwt5UYNAz/xKKimD6dDtzNy/Plmd+8EGQgnzmTJhH+6XTaLX2U8ILTrOr6/WsvvZ3HGx9iZ7Zq5rJGOoc3Uts+loa7V1HvcM7ATgW34bd3W5gd5fh7G838MxKc+PG2f9D27fD2rX29umn9oMhK+vsbps1g549z35D6NbNFiYt61qa8pxPLviKyDDgJcAFvG6MeaHU41HAdKA3cBgYZYzZ6X7st8Dd2PnsvzLGzL3QsZxI/llZ8NZbtlbP1q0wZMAp3nh4PS32LbNjO7/+GrKzya0TS1rf29ly6d1kteh+5vma/FUo2N3telqtnUWrtZ/SLPUrwgtOkx9ZmwOt+7O/7eX0efBS6NHDlptwKx5BdPKk/RDYsweio2H1atiyxS5KBhAebgdUtG8Pycn2GlvLlvaDomlTe4vW1UwvyOvJX0RcwA/AUCAdWAGMMcZsKtHmfqCbMeZeERkN3GyMGSUinYD3gL5AM2A+0N4YU25hE68nf2Moyi8k78Rpco7lkZV+iiN7sjm04wQ7V2dxcEMm2dsO0LxwF70b7qBrrTTq7U9Fiors89u2haFD2bBJONK0s1beVAoIK8ij/oFUGmVsov7BrdQ5mo64c8mpek3IataZ7NgkTsS24mSDRE7HxJIbE0derfrcemcdqFOH00SxOS2C9VsimPFBGBn7hQMHhawsyM01hFGEi0JcFBJBPo1i8kloZG9x9fOJrZtHw5h86tUuICa6gJjaRdSKNkRHGaKihcgoISIqjIg6EYRHheOKjiC8diRhURG4oiMIi7I3iYwgLDIcCXchYXJORQxj7K2oyP4sLLS3oqKz28BW0QgLszeXy36LCQ+3t+L7Lpdvq234Ivn3B542xlzj/v23AMaYP5doM9fdZqmIhAP7gXjg8ZJtS7Yr73hVTv4pKWcHRbv/VYoKCgkzRR49vbB2DK42ybY8Z7du9ntp795n1mRcfIee3StVHldeDnUP76DO0b3UObqX2scyiD6ZRWTucadDq5QihCLCztwMcuYGkEUjWrKnyvsXsR8CYWFnPzCKPxBE4JZbYNq0qu7b+xd8m8M5f2060K+8NsaYAhE5BsS6t39f6rnnrXUlIuOA4jEA2SKS6lH03nQqG9avt7dPP63ss+OAQz6IqqbQ16d8+tqUz4HXxmB7qMvrnDgFVP303ZizXV1lmT7d3jxQ1mvTqjKxeJL8y/pLS39dKK+NJ8/FGDMFCNpTaxFJqcwnbqjR16d8+tqUT1+b8nnjtfFkGcd0oOQArURgX3lt3N0+9YEsD5+rlFLKzzxJ/iuAdiKSLCKRwGhgVqk2s4Cx7vsjgYXGXkyYBYwWkSgRSQbaAcu9E7pSSqmqqrDbx92HPx6Yix3q+YYxZqOIPAOkGGNmAVOBt0UkDXvGP9r93I0i8gGwCSgAfnmhkT5BLGi7rPxEX5/y6WtTPn1tylft1ybgJnkppZTyPU+6fZRSStUwmvyVUioEafKvJBFpISJfichmEdkoIg+6tzcSkXkistX9M2SL3IqIS0RWi8jn7t+TRWSZ+7V53z1wIOSISAMR+VBEtrjfP/31fXOWiDzs/j+1QUTeE5HoUH3viMgbInJQRDaU2Fbme0Wsf4pImoisE5FenhxDk3/lFQC/NsZcBFwC/NJdxuJxYIExph2wwP17qHoQ2Fzi94nAJPdrcwRb6ykUvQR8aYzpCHTHvkb6vgFEpDnwK6CPMaYLdnDJaEL3vfMWMKzUtvLeK8OxIynbYSfLvurJATT5V5IxJsMYs8p9/wT2P3BzYARQPDF7GnCTMxE6S0QSgeuA192/C3AV8KG7SUi+NiJSDxiIHRmHMSbPGHMUfd+UFA7Ucs8Vqg1kEKLvHWPMYuzIyZLKe6+MAKYb63uggYg0regYmvyrQUSSgJ7AMiDBGJMB9gMCaOxcZI56EXgMKC6qFAscNcYUT2ovs8RHCGgNZAJvurvEXheROuj7BgBjzF7gb8BubNI/hl1HTN87Z5X3XimrBE+Fr5Mm/yoSkRjgI+AhY0xwVa/yERG5HjhojCm5+J9HJT5CQDjQC3jVGNMTOEmIdvGUxd1/PQJIxlYAroPtzigtFN87FanS/zFN/lUgIhHYxP+uMWame/OB4q9a7p8HnYrPQZcCN4rITmAG9iv7i9ivocUTCkO1xEc6kG6MWeb+/UPsh4G+b6whwA5jTKYxJh+YCQxA3zsllfdeqVIZHU3+leTuw54KbDbG/KPEQyVLXIwFKl0aNNgZY35rjEk0xiRhL9YtNMb8GPgKW/YDQve12Q/sEZEO7k2DsTPfQ/5947YbuEREarv/jxW/PiH/3imhvPfKLOCn7lE/lwDHiruHLkRn+FaSiFwGLAHWc7Zf+wlsv/8HQEvsG/lWY0zpCzYhQ0QGAY8YY64XkdbYbwKNgNXAHcaY007G5wQR6YG9EB4JbAfuwp6A6fsGEJE/AqOwI+pWA/dg+65D7r0jIu8Bg7Clmw8ATwGfUMZ7xf1h+TJ2dNAp4C5jTIWLomjyV0qpEKTdPkopFYI0+SulVAjS5K+UUiFIk79SSoUgTf5KKRWCNPkrVYKI3CwiRkQ6Oh2LUr6kyV+pc40BvsG9FKlSNZUmf6Xc3PWaLsWWDR7t3hYmIq+468x/LiKzRWSk+7HeIrJIRFaKyFxPKikqFSg0+St11k3Yevs/AFnuRTF+BCQBXbEzTvvDmfpO/weMNMb0Bt4AnnMiaKWqIrziJkqFjDHYQnRgSwqMASKA/xpjioD9IvKV+/EOQBdgnp1djwtbilipoKDJXylARGKxVUi7iIjBJnMDfFzeU4CNxpj+fgpRKa/Sbh+lrJHY1ZBaGWOSjDEtgB3AIeAWd99/ArbYFkAqEC8iZ7qBRKSzE4ErVRWa/JWyxnD+Wf5H2IVF0oENwGvY6q3HjDF52A+MiSKyFliDrT+vVFDQqp5KVUBEYowx2e6uoeXApe76/EoFLe3zV6pin4tIA2wd/j9p4lc1gZ75K6VUCNI+f6WUCkGa/JVSKgRp8ldKqRCkyV8ppUKQJn+llApB/w+oqklcj+r9JAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df['Age'][df['Exited']==0],color='blue',label='non-exited')\n",
    "sns.distplot(df['Age'][df['Exited']==1],color='red',label='exited')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age distribution of customers who exited bank is normally distributed while those who stays with bank is right skewed\n",
    "indicating that most of the existing customers of bank are lower than 50 years of age. This may also indicate that\n",
    "old age customers have exited the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Drop the columns which are unique for all users like IDs & 3. Distinguish the feature and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age',\n",
       "       'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
       "       'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into feature and Target set. Also CustomerId and Surname will not contribute to model building\n",
    "#hence we wil drop these 2 colmns as well\n",
    "X=df.drop(labels=['CustomerId','Surname','Exited'], axis=1) # Feature Set\n",
    "y=df['Exited'] # Target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geography and gender are object type, we will convert this into one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  int64  \n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Geography_France   10000 non-null  uint8  \n",
      " 9   Geography_Germany  10000 non-null  uint8  \n",
      " 10  Geography_Spain    10000 non-null  uint8  \n",
      " 11  Gender_Female      10000 non-null  uint8  \n",
      " 12  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(6), uint8(5)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object columns- Geography and Genders have been converted to one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Check first few rows of feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "RowNumber                                                                  \n",
       "1                  619   42       2       0.00              1          1   \n",
       "2                  608   41       1   83807.86              1          0   \n",
       "3                  502   42       8  159660.80              3          1   \n",
       "4                  699   39       1       0.00              2          0   \n",
       "5                  850   43       2  125510.82              1          1   \n",
       "\n",
       "           IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "RowNumber                                                      \n",
       "1                       1        101348.88                 1   \n",
       "2                       1        112542.58                 0   \n",
       "3                       0        113931.57                 1   \n",
       "4                       0         93826.63                 1   \n",
       "5                       1         79084.10                 0   \n",
       "\n",
       "           Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "RowNumber                                                                  \n",
       "1                          0                0              1            0  \n",
       "2                          0                1              1            0  \n",
       "3                          0                0              1            0  \n",
       "4                          0                0              1            0  \n",
       "5                          0                1              1            0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Divide the data set into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#test train split\n",
    "test_size = 0.30 # taking 70:30 training and test set\n",
    "seed = 7  # Random numbmer seeding for reapeatability of the code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 13), (3000, 13), (7000,), (3000,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hCheck Shape of test/trainset\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Normalize the train and test data \n",
    "\n",
    "a)Normalise Following features using standard scaler: CreditScore,Age, tenure,Balance,NumOfProducts,EstimatedSalary as these  have running/continuous values\n",
    "\n",
    "b)We will not normalise following features as they have discrete values either 0 or 1: HasCrCard,IsActiveMember,Geography_France,Geography_Germany,Geography_Spain,Gender_Female,Gender_Male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>630</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>110414.48</td>\n",
       "      <td>1</td>\n",
       "      <td>48984.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>850</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>54901.01</td>\n",
       "      <td>1</td>\n",
       "      <td>140075.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Age  Tenure    Balance  NumOfProducts  EstimatedSalary\n",
       "RowNumber                                                                     \n",
       "2318               630   36       2  110414.48              1         48984.95\n",
       "260                850   38       3   54901.01              1        140075.55"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>630</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>110414.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48984.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>850</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>54901.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140075.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "RowNumber                                                                  \n",
       "2318               630   36       2  110414.48              1          1   \n",
       "260                850   38       3   54901.01              1          1   \n",
       "\n",
       "           IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "RowNumber                                                      \n",
       "2318                    1         48984.95                 1   \n",
       "260                     1        140075.55                 0   \n",
       "\n",
       "           Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "RowNumber                                                                  \n",
       "2318                       0                0              1            0  \n",
       "260                        1                0              0            1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test set on the same fit as train set\n",
    "X_test_scaled=scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following step puts back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>-0.212665</td>\n",
       "      <td>-0.275584</td>\n",
       "      <td>-1.044043</td>\n",
       "      <td>0.535759</td>\n",
       "      <td>-0.902887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.885624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2.072829</td>\n",
       "      <td>-0.085732</td>\n",
       "      <td>-0.699815</td>\n",
       "      <td>-0.354525</td>\n",
       "      <td>-0.902887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
       "RowNumber                                                             \n",
       "2318         -0.212665 -0.275584 -1.044043  0.535759      -0.902887   \n",
       "260           2.072829 -0.085732 -0.699815 -0.354525      -0.902887   \n",
       "\n",
       "           HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "RowNumber                                                                 \n",
       "2318               1               1        -0.885624                 1   \n",
       "260                1               1         0.690326                 0   \n",
       "\n",
       "           Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "RowNumber                                                                  \n",
       "2318                       0                0              1            0  \n",
       "260                        1                0              0            1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.691144</td>\n",
       "      <td>-0.370510</td>\n",
       "      <td>-1.388270</td>\n",
       "      <td>-1.234987</td>\n",
       "      <td>2.518064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.290574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>0.275599</td>\n",
       "      <td>3.141754</td>\n",
       "      <td>1.021323</td>\n",
       "      <td>-1.234987</td>\n",
       "      <td>0.807589</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
       "RowNumber                                                             \n",
       "1978          0.691144 -0.370510 -1.388270 -1.234987       2.518064   \n",
       "3881          0.275599  3.141754  1.021323 -1.234987       0.807589   \n",
       "\n",
       "           HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "RowNumber                                                                 \n",
       "1978               0               0         1.290574                 0   \n",
       "3881               1               1         0.924388                 1   \n",
       "\n",
       "           Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "RowNumber                                                                  \n",
       "1978                       0                1              0            1  \n",
       "3881                       0                0              1            0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Data into Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data into Numpy arrays\n",
    "X_train_array=np.array(X_train)\n",
    "X_test_array=np.array(X_test)\n",
    "y_train_array=np.array(y_train)\n",
    "y_test_array=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 13), (3000, 13), (7000,), (3000,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_array.shape,X_test_array.shape,y_train_array.shape,y_test_array.shape#check shapes of array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Initialize & build the model (Basic Model with 2 hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Input layer to the model\n",
    "model.add(tf.keras.Input(shape=(13,))) # 13 Features\n",
    "\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_2'))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 359\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/150\n",
      "7000/7000 [==============================] - 1s 125us/sample - loss: 0.6041 - accuracy: 0.6780 - val_loss: 0.4772 - val_accuracy: 0.7950\n",
      "Epoch 2/150\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4546 - accuracy: 0.7937 - val_loss: 0.4288 - val_accuracy: 0.8050\n",
      "Epoch 3/150\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4256 - accuracy: 0.8087 - val_loss: 0.4091 - val_accuracy: 0.8243\n",
      "Epoch 4/150\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.82 - 0s 53us/sample - loss: 0.4058 - accuracy: 0.8293 - val_loss: 0.3846 - val_accuracy: 0.8407\n",
      "Epoch 5/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3855 - accuracy: 0.8440 - val_loss: 0.3686 - val_accuracy: 0.8487\n",
      "Epoch 6/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3735 - accuracy: 0.8456 - val_loss: 0.3580 - val_accuracy: 0.8520\n",
      "Epoch 7/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3674 - accuracy: 0.8463 - val_loss: 0.3537 - val_accuracy: 0.8530\n",
      "Epoch 8/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3592 - accuracy: 0.8524 - val_loss: 0.3501 - val_accuracy: 0.8543\n",
      "Epoch 9/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3606 - accuracy: 0.8494 - val_loss: 0.3483 - val_accuracy: 0.8563\n",
      "Epoch 10/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3565 - accuracy: 0.8510 - val_loss: 0.3460 - val_accuracy: 0.8563\n",
      "Epoch 11/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3535 - accuracy: 0.8569 - val_loss: 0.3461 - val_accuracy: 0.8577\n",
      "Epoch 12/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3533 - accuracy: 0.8550 - val_loss: 0.3443 - val_accuracy: 0.8560\n",
      "Epoch 13/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3487 - accuracy: 0.8531 - val_loss: 0.3435 - val_accuracy: 0.8570\n",
      "Epoch 14/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3557 - accuracy: 0.8516 - val_loss: 0.3434 - val_accuracy: 0.8583\n",
      "Epoch 15/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3527 - accuracy: 0.8561 - val_loss: 0.3422 - val_accuracy: 0.8597\n",
      "Epoch 16/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3508 - accuracy: 0.8561 - val_loss: 0.3417 - val_accuracy: 0.8573\n",
      "Epoch 17/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3471 - accuracy: 0.8573 - val_loss: 0.3404 - val_accuracy: 0.8587\n",
      "Epoch 18/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3513 - accuracy: 0.8537 - val_loss: 0.3415 - val_accuracy: 0.8577\n",
      "Epoch 19/150\n",
      "7000/7000 [==============================] - 0s 65us/sample - loss: 0.3454 - accuracy: 0.8543 - val_loss: 0.3405 - val_accuracy: 0.8580\n",
      "Epoch 20/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3502 - accuracy: 0.8557 - val_loss: 0.3405 - val_accuracy: 0.8617\n",
      "Epoch 21/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3460 - accuracy: 0.8571 - val_loss: 0.3409 - val_accuracy: 0.8613\n",
      "Epoch 22/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3446 - accuracy: 0.8581 - val_loss: 0.3397 - val_accuracy: 0.8583\n",
      "Epoch 23/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3486 - accuracy: 0.8539 - val_loss: 0.3396 - val_accuracy: 0.8597\n",
      "Epoch 24/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3457 - accuracy: 0.8599 - val_loss: 0.3391 - val_accuracy: 0.8600\n",
      "Epoch 25/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3447 - accuracy: 0.8583 - val_loss: 0.3397 - val_accuracy: 0.8607\n",
      "Epoch 26/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3453 - accuracy: 0.8571 - val_loss: 0.3390 - val_accuracy: 0.8610\n",
      "Epoch 27/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3461 - accuracy: 0.8571 - val_loss: 0.3389 - val_accuracy: 0.8617\n",
      "Epoch 28/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3409 - accuracy: 0.8593 - val_loss: 0.3396 - val_accuracy: 0.8603\n",
      "Epoch 29/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3433 - accuracy: 0.8553 - val_loss: 0.3388 - val_accuracy: 0.8603\n",
      "Epoch 30/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3459 - accuracy: 0.8557 - val_loss: 0.3390 - val_accuracy: 0.8617\n",
      "Epoch 31/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3429 - accuracy: 0.8573 - val_loss: 0.3390 - val_accuracy: 0.8620\n",
      "Epoch 32/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3414 - accuracy: 0.8576 - val_loss: 0.3396 - val_accuracy: 0.8623\n",
      "Epoch 33/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3401 - accuracy: 0.8577 - val_loss: 0.3411 - val_accuracy: 0.8607\n",
      "Epoch 34/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3429 - accuracy: 0.8617 - val_loss: 0.3386 - val_accuracy: 0.8613\n",
      "Epoch 35/150\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.85 - 0s 52us/sample - loss: 0.3403 - accuracy: 0.8586 - val_loss: 0.3394 - val_accuracy: 0.8597\n",
      "Epoch 36/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3409 - accuracy: 0.8569 - val_loss: 0.3405 - val_accuracy: 0.8580\n",
      "Epoch 37/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3412 - accuracy: 0.8600 - val_loss: 0.3398 - val_accuracy: 0.8613\n",
      "Epoch 38/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3412 - accuracy: 0.8586 - val_loss: 0.3386 - val_accuracy: 0.8620\n",
      "Epoch 39/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3389 - accuracy: 0.8600 - val_loss: 0.3389 - val_accuracy: 0.8603\n",
      "Epoch 40/150\n",
      "7000/7000 [==============================] - 0s 58us/sample - loss: 0.3366 - accuracy: 0.8583 - val_loss: 0.3387 - val_accuracy: 0.8573\n",
      "Epoch 41/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3368 - accuracy: 0.8627 - val_loss: 0.3379 - val_accuracy: 0.8590\n",
      "Epoch 42/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3406 - accuracy: 0.8583 - val_loss: 0.3382 - val_accuracy: 0.8600\n",
      "Epoch 43/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3395 - accuracy: 0.8624 - val_loss: 0.3385 - val_accuracy: 0.8597\n",
      "Epoch 44/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.3433 - val_accuracy: 0.8570\n",
      "Epoch 45/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3401 - accuracy: 0.8600 - val_loss: 0.3388 - val_accuracy: 0.8593\n",
      "Epoch 46/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3386 - accuracy: 0.8603 - val_loss: 0.3379 - val_accuracy: 0.8590\n",
      "Epoch 47/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3346 - accuracy: 0.8604 - val_loss: 0.3387 - val_accuracy: 0.8607\n",
      "Epoch 48/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3383 - accuracy: 0.8593 - val_loss: 0.3388 - val_accuracy: 0.8597\n",
      "Epoch 49/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3392 - accuracy: 0.8576 - val_loss: 0.3388 - val_accuracy: 0.8567\n",
      "Epoch 50/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3391 - accuracy: 0.8603 - val_loss: 0.3386 - val_accuracy: 0.8593\n",
      "Epoch 51/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3368 - accuracy: 0.8587 - val_loss: 0.3372 - val_accuracy: 0.8597\n",
      "Epoch 52/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3345 - accuracy: 0.8620 - val_loss: 0.3379 - val_accuracy: 0.8617\n",
      "Epoch 53/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3379 - accuracy: 0.8603 - val_loss: 0.3371 - val_accuracy: 0.8627\n",
      "Epoch 54/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3349 - accuracy: 0.8604 - val_loss: 0.3376 - val_accuracy: 0.8577\n",
      "Epoch 55/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3361 - accuracy: 0.8589 - val_loss: 0.3372 - val_accuracy: 0.8617\n",
      "Epoch 56/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3383 - accuracy: 0.8590 - val_loss: 0.3368 - val_accuracy: 0.8597\n",
      "Epoch 57/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3334 - accuracy: 0.8620 - val_loss: 0.3363 - val_accuracy: 0.8587\n",
      "Epoch 58/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3373 - accuracy: 0.8600 - val_loss: 0.3370 - val_accuracy: 0.8593\n",
      "Epoch 59/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3368 - accuracy: 0.8600 - val_loss: 0.3394 - val_accuracy: 0.8577\n",
      "Epoch 60/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3396 - accuracy: 0.8606 - val_loss: 0.3364 - val_accuracy: 0.8627\n",
      "Epoch 61/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3366 - accuracy: 0.8633 - val_loss: 0.3377 - val_accuracy: 0.8573\n",
      "Epoch 62/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3340 - accuracy: 0.8621 - val_loss: 0.3384 - val_accuracy: 0.8573\n",
      "Epoch 63/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3357 - accuracy: 0.8603 - val_loss: 0.3357 - val_accuracy: 0.8610\n",
      "Epoch 64/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3330 - accuracy: 0.8607 - val_loss: 0.3364 - val_accuracy: 0.8633\n",
      "Epoch 65/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3341 - accuracy: 0.8609 - val_loss: 0.3371 - val_accuracy: 0.8567\n",
      "Epoch 66/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3360 - accuracy: 0.8593 - val_loss: 0.3349 - val_accuracy: 0.8607\n",
      "Epoch 67/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3360 - accuracy: 0.8604 - val_loss: 0.3350 - val_accuracy: 0.8623\n",
      "Epoch 68/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3379 - accuracy: 0.8607 - val_loss: 0.3364 - val_accuracy: 0.8580\n",
      "Epoch 69/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3383 - accuracy: 0.8571 - val_loss: 0.3357 - val_accuracy: 0.8603\n",
      "Epoch 70/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3318 - accuracy: 0.8606 - val_loss: 0.3373 - val_accuracy: 0.8593\n",
      "Epoch 71/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3303 - accuracy: 0.8640 - val_loss: 0.3359 - val_accuracy: 0.8593\n",
      "Epoch 72/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3340 - accuracy: 0.8616 - val_loss: 0.3372 - val_accuracy: 0.8607\n",
      "Epoch 73/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3356 - accuracy: 0.8574 - val_loss: 0.3369 - val_accuracy: 0.8577\n",
      "Epoch 74/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3332 - accuracy: 0.8641 - val_loss: 0.3373 - val_accuracy: 0.8627\n",
      "Epoch 75/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3361 - accuracy: 0.8597 - val_loss: 0.3356 - val_accuracy: 0.8600\n",
      "Epoch 76/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3349 - accuracy: 0.8594 - val_loss: 0.3358 - val_accuracy: 0.8613\n",
      "Epoch 77/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3410 - accuracy: 0.8531 - val_loss: 0.3361 - val_accuracy: 0.8597\n",
      "Epoch 78/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3349 - accuracy: 0.8614 - val_loss: 0.3382 - val_accuracy: 0.8570\n",
      "Epoch 79/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3297 - accuracy: 0.8631 - val_loss: 0.3370 - val_accuracy: 0.8590\n",
      "Epoch 80/150\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.86 - 0s 55us/sample - loss: 0.3368 - accuracy: 0.8637 - val_loss: 0.3355 - val_accuracy: 0.8593\n",
      "Epoch 81/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3349 - accuracy: 0.8607 - val_loss: 0.3353 - val_accuracy: 0.8603\n",
      "Epoch 82/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3336 - accuracy: 0.8580 - val_loss: 0.3357 - val_accuracy: 0.8597\n",
      "Epoch 83/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3392 - accuracy: 0.8597 - val_loss: 0.3378 - val_accuracy: 0.8577\n",
      "Epoch 84/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3340 - accuracy: 0.8621 - val_loss: 0.3357 - val_accuracy: 0.8587\n",
      "Epoch 85/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3312 - accuracy: 0.8641 - val_loss: 0.3378 - val_accuracy: 0.8577\n",
      "Epoch 86/150\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.3344 - accuracy: 0.8603 - val_loss: 0.3360 - val_accuracy: 0.8577\n",
      "Epoch 87/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3362 - accuracy: 0.8580 - val_loss: 0.3365 - val_accuracy: 0.8607\n",
      "Epoch 88/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3363 - accuracy: 0.8586 - val_loss: 0.3376 - val_accuracy: 0.8557\n",
      "Epoch 89/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3350 - accuracy: 0.8601 - val_loss: 0.3369 - val_accuracy: 0.8570\n",
      "Epoch 90/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3363 - accuracy: 0.8606 - val_loss: 0.3354 - val_accuracy: 0.8610\n",
      "Epoch 91/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3341 - accuracy: 0.8599 - val_loss: 0.3358 - val_accuracy: 0.8613\n",
      "Epoch 92/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3301 - accuracy: 0.8673 - val_loss: 0.3359 - val_accuracy: 0.8577\n",
      "Epoch 93/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3321 - accuracy: 0.8624 - val_loss: 0.3362 - val_accuracy: 0.8613\n",
      "Epoch 94/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3337 - accuracy: 0.8620 - val_loss: 0.3348 - val_accuracy: 0.8577\n",
      "Epoch 95/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3355 - accuracy: 0.8590 - val_loss: 0.3357 - val_accuracy: 0.8610\n",
      "Epoch 96/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3333 - accuracy: 0.8576 - val_loss: 0.3369 - val_accuracy: 0.8597\n",
      "Epoch 97/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3323 - accuracy: 0.8661 - val_loss: 0.3372 - val_accuracy: 0.8600\n",
      "Epoch 98/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3327 - accuracy: 0.8623 - val_loss: 0.3403 - val_accuracy: 0.8540\n",
      "Epoch 99/150\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.3365 - accuracy: 0.8566 - val_loss: 0.3385 - val_accuracy: 0.8580\n",
      "Epoch 100/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3352 - accuracy: 0.8630 - val_loss: 0.3371 - val_accuracy: 0.8600\n",
      "Epoch 101/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3327 - accuracy: 0.8620 - val_loss: 0.3370 - val_accuracy: 0.8600\n",
      "Epoch 102/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3316 - accuracy: 0.8640 - val_loss: 0.3370 - val_accuracy: 0.8593\n",
      "Epoch 103/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3321 - accuracy: 0.8593 - val_loss: 0.3369 - val_accuracy: 0.8603\n",
      "Epoch 104/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3329 - accuracy: 0.8643 - val_loss: 0.3360 - val_accuracy: 0.8610\n",
      "Epoch 105/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3345 - accuracy: 0.8610 - val_loss: 0.3356 - val_accuracy: 0.8627\n",
      "Epoch 106/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3327 - accuracy: 0.8601 - val_loss: 0.3368 - val_accuracy: 0.8593\n",
      "Epoch 107/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3323 - accuracy: 0.8607 - val_loss: 0.3356 - val_accuracy: 0.8623\n",
      "Epoch 108/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3398 - accuracy: 0.8561 - val_loss: 0.3353 - val_accuracy: 0.8620\n",
      "Epoch 109/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3336 - accuracy: 0.8600 - val_loss: 0.3357 - val_accuracy: 0.8627\n",
      "Epoch 110/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3308 - accuracy: 0.8634 - val_loss: 0.3361 - val_accuracy: 0.8600\n",
      "Epoch 111/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3354 - accuracy: 0.8623 - val_loss: 0.3369 - val_accuracy: 0.8603\n",
      "Epoch 112/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3322 - accuracy: 0.8607 - val_loss: 0.3360 - val_accuracy: 0.8590\n",
      "Epoch 113/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3356 - val_accuracy: 0.8627\n",
      "Epoch 114/150\n",
      "7000/7000 [==============================] - 0s 58us/sample - loss: 0.3327 - accuracy: 0.8604 - val_loss: 0.3364 - val_accuracy: 0.8577\n",
      "Epoch 115/150\n",
      "7000/7000 [==============================] - 0s 59us/sample - loss: 0.3340 - accuracy: 0.8607 - val_loss: 0.3357 - val_accuracy: 0.8630\n",
      "Epoch 116/150\n",
      "7000/7000 [==============================] - 0s 58us/sample - loss: 0.3312 - accuracy: 0.8593 - val_loss: 0.3367 - val_accuracy: 0.8593\n",
      "Epoch 117/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3327 - accuracy: 0.8579 - val_loss: 0.3362 - val_accuracy: 0.8610\n",
      "Epoch 118/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3357 - accuracy: 0.8616 - val_loss: 0.3361 - val_accuracy: 0.8587\n",
      "Epoch 119/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3334 - accuracy: 0.8601 - val_loss: 0.3362 - val_accuracy: 0.8577\n",
      "Epoch 120/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3357 - accuracy: 0.8574 - val_loss: 0.3362 - val_accuracy: 0.8577\n",
      "Epoch 121/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3324 - accuracy: 0.8591 - val_loss: 0.3352 - val_accuracy: 0.8613\n",
      "Epoch 122/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3346 - accuracy: 0.8609 - val_loss: 0.3359 - val_accuracy: 0.8587\n",
      "Epoch 123/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3333 - accuracy: 0.8604 - val_loss: 0.3360 - val_accuracy: 0.8597\n",
      "Epoch 124/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3351 - accuracy: 0.8587 - val_loss: 0.3352 - val_accuracy: 0.8600\n",
      "Epoch 125/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3361 - accuracy: 0.8593 - val_loss: 0.3351 - val_accuracy: 0.8640\n",
      "Epoch 126/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3333 - accuracy: 0.8639 - val_loss: 0.3364 - val_accuracy: 0.8600\n",
      "Epoch 127/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3320 - accuracy: 0.8619 - val_loss: 0.3373 - val_accuracy: 0.8577\n",
      "Epoch 128/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3352 - accuracy: 0.8607 - val_loss: 0.3392 - val_accuracy: 0.8597\n",
      "Epoch 129/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3326 - accuracy: 0.8603 - val_loss: 0.3365 - val_accuracy: 0.8623\n",
      "Epoch 130/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3344 - accuracy: 0.8626 - val_loss: 0.3366 - val_accuracy: 0.8600\n",
      "Epoch 131/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3275 - accuracy: 0.8629 - val_loss: 0.3356 - val_accuracy: 0.8580\n",
      "Epoch 132/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3314 - accuracy: 0.8626 - val_loss: 0.3359 - val_accuracy: 0.8593\n",
      "Epoch 133/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3314 - accuracy: 0.8619 - val_loss: 0.3359 - val_accuracy: 0.8633\n",
      "Epoch 134/150\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.3307 - accuracy: 0.8606 - val_loss: 0.3364 - val_accuracy: 0.8610\n",
      "Epoch 135/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3316 - accuracy: 0.8606 - val_loss: 0.3352 - val_accuracy: 0.8603\n",
      "Epoch 136/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3314 - accuracy: 0.8620 - val_loss: 0.3359 - val_accuracy: 0.8570\n",
      "Epoch 137/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3345 - accuracy: 0.8620 - val_loss: 0.3363 - val_accuracy: 0.8583\n",
      "Epoch 138/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3334 - accuracy: 0.8603 - val_loss: 0.3362 - val_accuracy: 0.8643\n",
      "Epoch 139/150\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.3309 - accuracy: 0.8603 - val_loss: 0.3385 - val_accuracy: 0.8603\n",
      "Epoch 140/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3336 - accuracy: 0.8601 - val_loss: 0.3362 - val_accuracy: 0.8633\n",
      "Epoch 141/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3281 - accuracy: 0.8644 - val_loss: 0.3361 - val_accuracy: 0.8657\n",
      "Epoch 142/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3305 - accuracy: 0.8654 - val_loss: 0.3368 - val_accuracy: 0.8597\n",
      "Epoch 143/150\n",
      "7000/7000 [==============================] - 0s 58us/sample - loss: 0.3321 - accuracy: 0.8636 - val_loss: 0.3362 - val_accuracy: 0.8600\n",
      "Epoch 144/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3295 - accuracy: 0.8636 - val_loss: 0.3367 - val_accuracy: 0.8617\n",
      "Epoch 145/150\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.3328 - accuracy: 0.8619 - val_loss: 0.3385 - val_accuracy: 0.8633\n",
      "Epoch 146/150\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.3325 - accuracy: 0.8620 - val_loss: 0.3378 - val_accuracy: 0.8637\n",
      "Epoch 147/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3314 - accuracy: 0.8614 - val_loss: 0.3358 - val_accuracy: 0.8603\n",
      "Epoch 148/150\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.3300 - accuracy: 0.8643 - val_loss: 0.3361 - val_accuracy: 0.8633\n",
      "Epoch 149/150\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.3272 - accuracy: 0.8637 - val_loss: 0.3391 - val_accuracy: 0.8590\n",
      "Epoch 150/150\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.3346 - accuracy: 0.8606 - val_loss: 0.3357 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d29339788>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Predict the results using 0.5 as a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46090513],\n",
       "       [0.01634943],\n",
       "       [0.01848349],\n",
       "       [0.6376873 ],\n",
       "       [0.03994632]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_array)[:5] # Observe first 5 probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5 # Threshold\n",
    "y_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_preds[:5] # Observe First 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2280,  115],\n",
       "       [ 305,  300]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix with optimal Threshold on test set\n",
    "metrics.confusion_matrix(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics at 0.5 Threshold with basic DNN model\n",
      "\n",
      "           Basic DNN\n",
      "accuracy    0.860000\n",
      "recall      0.495868\n",
      "precision   0.722892\n",
      "f1_score    0.588235\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics at 0.5 Threshold with basic DNN model\\n')\n",
    "Test_Metrics_Basic_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n",
    "                   recall_score(y_test, y_test_preds), \n",
    "                   precision_score(y_test, y_test_preds),\n",
    "                   f1_score(y_test, y_test_preds)], columns=['Basic DNN'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Metrics_Basic_DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "####  test set has actually 3000 customers data out of which (300+305=605) have actually churned \n",
    "####   (2289+115=2395) out of 3000 customers in test set have not churned  \n",
    "#### Model has correctly predicted 300/605 customers who have churned\n",
    "#### Model has predicted 2280/2395 Customers who have not churned correctly.\n",
    "#### Recall is poor ,because data set is biased and has less number of records for churned Customers\n",
    "##### Precision – Of all the users that the algorithm predicts will churn, how many of them do actually churn?\n",
    "##### Recall – What percentage of users that end up churning does the algorithm successfully find?\n",
    "#### Both precision and recall are important for evaluating the performance of a churn prediction algorithm. In this case recall is poor, we will try some tuning to get better recall and overall acuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) With 3 Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Input layer to the model\n",
    "model.add(tf.keras.Input(shape=(13,))) # 13 Features\n",
    "\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/150\n",
      "7000/7000 [==============================] - 2s 321us/sample - loss: 0.5120 - accuracy: 0.7636 - val_loss: 0.4513 - val_accuracy: 0.7977\n",
      "Epoch 2/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.4460 - accuracy: 0.8023 - val_loss: 0.4286 - val_accuracy: 0.8160\n",
      "Epoch 3/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.4291 - accuracy: 0.8140 - val_loss: 0.4145 - val_accuracy: 0.8197\n",
      "Epoch 4/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.4173 - accuracy: 0.8213 - val_loss: 0.4024 - val_accuracy: 0.8270\n",
      "Epoch 5/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.4028 - accuracy: 0.8280 - val_loss: 0.3855 - val_accuracy: 0.8413\n",
      "Epoch 6/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3833 - accuracy: 0.8456 - val_loss: 0.3644 - val_accuracy: 0.8517\n",
      "Epoch 7/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3699 - accuracy: 0.8483 - val_loss: 0.3590 - val_accuracy: 0.8553\n",
      "Epoch 8/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3621 - accuracy: 0.8494 - val_loss: 0.3508 - val_accuracy: 0.8580\n",
      "Epoch 9/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3554 - accuracy: 0.8550 - val_loss: 0.3476 - val_accuracy: 0.8567\n",
      "Epoch 10/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3589 - accuracy: 0.8516 - val_loss: 0.3456 - val_accuracy: 0.8587\n",
      "Epoch 11/150\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3566 - accuracy: 0.8521 - val_loss: 0.3461 - val_accuracy: 0.8577\n",
      "Epoch 12/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3556 - accuracy: 0.8549 - val_loss: 0.3440 - val_accuracy: 0.8607\n",
      "Epoch 13/150\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.3481 - accuracy: 0.8549 - val_loss: 0.3441 - val_accuracy: 0.8603\n",
      "Epoch 14/150\n",
      "7000/7000 [==============================] - 1s 118us/sample - loss: 0.3490 - accuracy: 0.8526 - val_loss: 0.3471 - val_accuracy: 0.8583\n",
      "Epoch 15/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3474 - accuracy: 0.8551 - val_loss: 0.3433 - val_accuracy: 0.8587\n",
      "Epoch 16/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3504 - accuracy: 0.8537 - val_loss: 0.3418 - val_accuracy: 0.8590\n",
      "Epoch 17/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3523 - accuracy: 0.8563 - val_loss: 0.3421 - val_accuracy: 0.8583\n",
      "Epoch 18/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3545 - accuracy: 0.8504 - val_loss: 0.3420 - val_accuracy: 0.8580\n",
      "Epoch 19/150\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.3468 - accuracy: 0.8557 - val_loss: 0.3430 - val_accuracy: 0.8603\n",
      "Epoch 20/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3449 - accuracy: 0.8589 - val_loss: 0.3419 - val_accuracy: 0.8583\n",
      "Epoch 21/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3481 - accuracy: 0.8564 - val_loss: 0.3416 - val_accuracy: 0.8607\n",
      "Epoch 22/150\n",
      "7000/7000 [==============================] - 1s 118us/sample - loss: 0.3465 - accuracy: 0.8571 - val_loss: 0.3424 - val_accuracy: 0.8597\n",
      "Epoch 23/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3458 - accuracy: 0.8569 - val_loss: 0.3409 - val_accuracy: 0.8590\n",
      "Epoch 24/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3461 - accuracy: 0.8567 - val_loss: 0.3422 - val_accuracy: 0.8580\n",
      "Epoch 25/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3479 - accuracy: 0.8557 - val_loss: 0.3419 - val_accuracy: 0.8610\n",
      "Epoch 26/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3441 - accuracy: 0.8590 - val_loss: 0.3411 - val_accuracy: 0.8603\n",
      "Epoch 27/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3443 - accuracy: 0.8556 - val_loss: 0.3442 - val_accuracy: 0.8570\n",
      "Epoch 28/150\n",
      "7000/7000 [==============================] - 1s 124us/sample - loss: 0.3457 - accuracy: 0.8549 - val_loss: 0.3405 - val_accuracy: 0.8587\n",
      "Epoch 29/150\n",
      "7000/7000 [==============================] - 1s 126us/sample - loss: 0.3462 - accuracy: 0.8560 - val_loss: 0.3422 - val_accuracy: 0.8557\n",
      "Epoch 30/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3427 - accuracy: 0.8570 - val_loss: 0.3416 - val_accuracy: 0.8583\n",
      "Epoch 31/150\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3405 - accuracy: 0.8591 - val_loss: 0.3431 - val_accuracy: 0.8550\n",
      "Epoch 32/150\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3434 - accuracy: 0.8569 - val_loss: 0.3430 - val_accuracy: 0.8570\n",
      "Epoch 33/150\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3419 - accuracy: 0.8587 - val_loss: 0.3425 - val_accuracy: 0.8580\n",
      "Epoch 34/150\n",
      "7000/7000 [==============================] - 1s 125us/sample - loss: 0.3415 - accuracy: 0.8603 - val_loss: 0.3425 - val_accuracy: 0.8587\n",
      "Epoch 35/150\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3405 - accuracy: 0.8563 - val_loss: 0.3426 - val_accuracy: 0.8600\n",
      "Epoch 36/150\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3367 - accuracy: 0.8624 - val_loss: 0.3415 - val_accuracy: 0.8613\n",
      "Epoch 37/150\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3404 - accuracy: 0.8569 - val_loss: 0.3421 - val_accuracy: 0.8597\n",
      "Epoch 38/150\n",
      "7000/7000 [==============================] - 1s 96us/sample - loss: 0.3383 - accuracy: 0.8569 - val_loss: 0.3425 - val_accuracy: 0.8563\n",
      "Epoch 39/150\n",
      "7000/7000 [==============================] - 1s 125us/sample - loss: 0.3393 - accuracy: 0.8571 - val_loss: 0.3443 - val_accuracy: 0.8597\n",
      "Epoch 40/150\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.3406 - accuracy: 0.8590 - val_loss: 0.3425 - val_accuracy: 0.8600\n",
      "Epoch 41/150\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.3355 - accuracy: 0.8594 - val_loss: 0.3440 - val_accuracy: 0.8553\n",
      "Epoch 42/150\n",
      "7000/7000 [==============================] - 1s 130us/sample - loss: 0.3382 - accuracy: 0.8606 - val_loss: 0.3424 - val_accuracy: 0.8603\n",
      "Epoch 43/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3374 - accuracy: 0.8583 - val_loss: 0.3430 - val_accuracy: 0.8587\n",
      "Epoch 44/150\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3406 - accuracy: 0.8561 - val_loss: 0.3414 - val_accuracy: 0.8533\n",
      "Epoch 45/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3387 - accuracy: 0.8627 - val_loss: 0.3434 - val_accuracy: 0.8600\n",
      "Epoch 46/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3387 - accuracy: 0.8587 - val_loss: 0.3412 - val_accuracy: 0.8573\n",
      "Epoch 47/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3367 - accuracy: 0.8633 - val_loss: 0.3418 - val_accuracy: 0.8563\n",
      "Epoch 48/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3382 - accuracy: 0.8593 - val_loss: 0.3430 - val_accuracy: 0.8547\n",
      "Epoch 49/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3376 - accuracy: 0.8561 - val_loss: 0.3425 - val_accuracy: 0.8570\n",
      "Epoch 50/150\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3339 - accuracy: 0.8640 - val_loss: 0.3418 - val_accuracy: 0.8600\n",
      "Epoch 51/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3396 - accuracy: 0.8567 - val_loss: 0.3411 - val_accuracy: 0.8563\n",
      "Epoch 52/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3363 - accuracy: 0.8601 - val_loss: 0.3414 - val_accuracy: 0.8547\n",
      "Epoch 53/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3351 - accuracy: 0.8596 - val_loss: 0.3417 - val_accuracy: 0.8567\n",
      "Epoch 54/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3368 - accuracy: 0.8609 - val_loss: 0.3422 - val_accuracy: 0.8590\n",
      "Epoch 55/150\n",
      "7000/7000 [==============================] - 1s 105us/sample - loss: 0.3364 - accuracy: 0.8589 - val_loss: 0.3438 - val_accuracy: 0.8587\n",
      "Epoch 56/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3329 - accuracy: 0.8600 - val_loss: 0.3443 - val_accuracy: 0.8523\n",
      "Epoch 57/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3349 - accuracy: 0.8633 - val_loss: 0.3417 - val_accuracy: 0.8557\n",
      "Epoch 58/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3328 - accuracy: 0.8636 - val_loss: 0.3426 - val_accuracy: 0.8553\n",
      "Epoch 59/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3327 - accuracy: 0.8623 - val_loss: 0.3451 - val_accuracy: 0.8540\n",
      "Epoch 60/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3334 - accuracy: 0.8616 - val_loss: 0.3416 - val_accuracy: 0.8557\n",
      "Epoch 61/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3368 - accuracy: 0.8623 - val_loss: 0.3421 - val_accuracy: 0.8583\n",
      "Epoch 62/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3318 - accuracy: 0.8591 - val_loss: 0.3445 - val_accuracy: 0.8563\n",
      "Epoch 63/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3330 - accuracy: 0.8573 - val_loss: 0.3430 - val_accuracy: 0.8557\n",
      "Epoch 64/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3292 - accuracy: 0.8627 - val_loss: 0.3449 - val_accuracy: 0.8573\n",
      "Epoch 65/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3346 - accuracy: 0.8599 - val_loss: 0.3438 - val_accuracy: 0.8580\n",
      "Epoch 66/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3356 - accuracy: 0.8591 - val_loss: 0.3434 - val_accuracy: 0.8553\n",
      "Epoch 67/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3350 - accuracy: 0.8621 - val_loss: 0.3429 - val_accuracy: 0.8547\n",
      "Epoch 68/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3329 - accuracy: 0.8634 - val_loss: 0.3444 - val_accuracy: 0.8533\n",
      "Epoch 69/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3311 - accuracy: 0.8651 - val_loss: 0.3438 - val_accuracy: 0.8560\n",
      "Epoch 70/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3337 - accuracy: 0.8627 - val_loss: 0.3448 - val_accuracy: 0.8533\n",
      "Epoch 71/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3353 - accuracy: 0.8601 - val_loss: 0.3411 - val_accuracy: 0.8573\n",
      "Epoch 72/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3343 - accuracy: 0.8631 - val_loss: 0.3439 - val_accuracy: 0.8583\n",
      "Epoch 73/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3311 - accuracy: 0.8649 - val_loss: 0.3448 - val_accuracy: 0.8533\n",
      "Epoch 74/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3318 - accuracy: 0.8644 - val_loss: 0.3435 - val_accuracy: 0.8557\n",
      "Epoch 75/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3322 - accuracy: 0.8623 - val_loss: 0.3433 - val_accuracy: 0.8577\n",
      "Epoch 76/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3342 - accuracy: 0.8594 - val_loss: 0.3432 - val_accuracy: 0.8560\n",
      "Epoch 77/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3435 - val_accuracy: 0.8563\n",
      "Epoch 78/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3329 - accuracy: 0.8594 - val_loss: 0.3436 - val_accuracy: 0.8553\n",
      "Epoch 79/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3331 - accuracy: 0.8613 - val_loss: 0.3420 - val_accuracy: 0.8570\n",
      "Epoch 80/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3455 - val_accuracy: 0.8527\n",
      "Epoch 81/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3306 - accuracy: 0.8640 - val_loss: 0.3461 - val_accuracy: 0.8543\n",
      "Epoch 82/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3338 - accuracy: 0.8609 - val_loss: 0.3452 - val_accuracy: 0.8557\n",
      "Epoch 83/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3309 - accuracy: 0.8603 - val_loss: 0.3464 - val_accuracy: 0.8520\n",
      "Epoch 84/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3316 - accuracy: 0.8623 - val_loss: 0.3444 - val_accuracy: 0.8550\n",
      "Epoch 85/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3281 - accuracy: 0.8653 - val_loss: 0.3426 - val_accuracy: 0.8557\n",
      "Epoch 86/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3312 - accuracy: 0.8623 - val_loss: 0.3436 - val_accuracy: 0.8533\n",
      "Epoch 87/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3306 - accuracy: 0.8620 - val_loss: 0.3447 - val_accuracy: 0.8530\n",
      "Epoch 88/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3287 - accuracy: 0.8674 - val_loss: 0.3448 - val_accuracy: 0.8540\n",
      "Epoch 89/150\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3341 - accuracy: 0.8621 - val_loss: 0.3436 - val_accuracy: 0.8570\n",
      "Epoch 90/150\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3301 - accuracy: 0.8636 - val_loss: 0.3447 - val_accuracy: 0.8540\n",
      "Epoch 91/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3301 - accuracy: 0.8644 - val_loss: 0.3441 - val_accuracy: 0.8560\n",
      "Epoch 92/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3271 - accuracy: 0.8660 - val_loss: 0.3452 - val_accuracy: 0.8553\n",
      "Epoch 93/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3302 - accuracy: 0.8636 - val_loss: 0.3428 - val_accuracy: 0.8537\n",
      "Epoch 94/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3343 - accuracy: 0.8587 - val_loss: 0.3439 - val_accuracy: 0.8570\n",
      "Epoch 95/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3443 - val_accuracy: 0.8560\n",
      "Epoch 96/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3292 - accuracy: 0.8651 - val_loss: 0.3442 - val_accuracy: 0.8563\n",
      "Epoch 97/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3311 - accuracy: 0.8614 - val_loss: 0.3471 - val_accuracy: 0.8540\n",
      "Epoch 98/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3305 - accuracy: 0.8639 - val_loss: 0.3460 - val_accuracy: 0.8543\n",
      "Epoch 99/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3283 - accuracy: 0.8626 - val_loss: 0.3446 - val_accuracy: 0.8553\n",
      "Epoch 100/150\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.3280 - accuracy: 0.8666 - val_loss: 0.3444 - val_accuracy: 0.8567\n",
      "Epoch 101/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3294 - accuracy: 0.8651 - val_loss: 0.3469 - val_accuracy: 0.8570\n",
      "Epoch 102/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3298 - accuracy: 0.8646 - val_loss: 0.3474 - val_accuracy: 0.8547\n",
      "Epoch 103/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3270 - accuracy: 0.8646 - val_loss: 0.3487 - val_accuracy: 0.8557\n",
      "Epoch 104/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3316 - accuracy: 0.8649 - val_loss: 0.3456 - val_accuracy: 0.8557\n",
      "Epoch 105/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3299 - accuracy: 0.8621 - val_loss: 0.3446 - val_accuracy: 0.8560\n",
      "Epoch 106/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3321 - accuracy: 0.8629 - val_loss: 0.3468 - val_accuracy: 0.8570\n",
      "Epoch 107/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3287 - accuracy: 0.8651 - val_loss: 0.3465 - val_accuracy: 0.8547\n",
      "Epoch 108/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3262 - accuracy: 0.8619 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 109/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3307 - accuracy: 0.8617 - val_loss: 0.3460 - val_accuracy: 0.8570\n",
      "Epoch 110/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3304 - accuracy: 0.8627 - val_loss: 0.3467 - val_accuracy: 0.8557\n",
      "Epoch 111/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3298 - accuracy: 0.8621 - val_loss: 0.3472 - val_accuracy: 0.8547\n",
      "Epoch 112/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3304 - accuracy: 0.8650 - val_loss: 0.3453 - val_accuracy: 0.8543\n",
      "Epoch 113/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3317 - accuracy: 0.8611 - val_loss: 0.3465 - val_accuracy: 0.8553\n",
      "Epoch 114/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3315 - accuracy: 0.8610 - val_loss: 0.3491 - val_accuracy: 0.8527\n",
      "Epoch 115/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3310 - accuracy: 0.8604 - val_loss: 0.3481 - val_accuracy: 0.8557\n",
      "Epoch 116/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3297 - accuracy: 0.8653 - val_loss: 0.3494 - val_accuracy: 0.8540\n",
      "Epoch 117/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3260 - accuracy: 0.8659 - val_loss: 0.3473 - val_accuracy: 0.8537\n",
      "Epoch 118/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3232 - accuracy: 0.8650 - val_loss: 0.3492 - val_accuracy: 0.8580\n",
      "Epoch 119/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3301 - accuracy: 0.8623 - val_loss: 0.3478 - val_accuracy: 0.8560\n",
      "Epoch 120/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3278 - accuracy: 0.8630 - val_loss: 0.3467 - val_accuracy: 0.8550\n",
      "Epoch 121/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3298 - accuracy: 0.8630 - val_loss: 0.3461 - val_accuracy: 0.8587\n",
      "Epoch 122/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3288 - accuracy: 0.8657 - val_loss: 0.3469 - val_accuracy: 0.8597\n",
      "Epoch 123/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3291 - accuracy: 0.8666 - val_loss: 0.3454 - val_accuracy: 0.8550\n",
      "Epoch 124/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3249 - accuracy: 0.8661 - val_loss: 0.3469 - val_accuracy: 0.8577\n",
      "Epoch 125/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3319 - accuracy: 0.8606 - val_loss: 0.3454 - val_accuracy: 0.8553\n",
      "Epoch 126/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3289 - accuracy: 0.8647 - val_loss: 0.3480 - val_accuracy: 0.8563\n",
      "Epoch 127/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3238 - accuracy: 0.8653 - val_loss: 0.3487 - val_accuracy: 0.8563\n",
      "Epoch 128/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3265 - accuracy: 0.8639 - val_loss: 0.3488 - val_accuracy: 0.8543\n",
      "Epoch 129/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3266 - accuracy: 0.8633 - val_loss: 0.3477 - val_accuracy: 0.8540\n",
      "Epoch 130/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3263 - accuracy: 0.8669 - val_loss: 0.3499 - val_accuracy: 0.8530\n",
      "Epoch 131/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3266 - accuracy: 0.8654 - val_loss: 0.3473 - val_accuracy: 0.8567\n",
      "Epoch 132/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3261 - accuracy: 0.8653 - val_loss: 0.3489 - val_accuracy: 0.8543\n",
      "Epoch 133/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3224 - accuracy: 0.8659 - val_loss: 0.3492 - val_accuracy: 0.8607\n",
      "Epoch 134/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3232 - accuracy: 0.8664 - val_loss: 0.3468 - val_accuracy: 0.8537\n",
      "Epoch 135/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3305 - accuracy: 0.8623 - val_loss: 0.3473 - val_accuracy: 0.8583\n",
      "Epoch 136/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3279 - accuracy: 0.8644 - val_loss: 0.3467 - val_accuracy: 0.8587\n",
      "Epoch 137/150\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3274 - accuracy: 0.8631 - val_loss: 0.3476 - val_accuracy: 0.8593\n",
      "Epoch 138/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3289 - accuracy: 0.8633 - val_loss: 0.3493 - val_accuracy: 0.8563\n",
      "Epoch 139/150\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3268 - accuracy: 0.8657 - val_loss: 0.3472 - val_accuracy: 0.8567\n",
      "Epoch 140/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3262 - accuracy: 0.8633 - val_loss: 0.3525 - val_accuracy: 0.8520\n",
      "Epoch 141/150\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3267 - accuracy: 0.8637 - val_loss: 0.3478 - val_accuracy: 0.8573\n",
      "Epoch 142/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3255 - accuracy: 0.8629 - val_loss: 0.3487 - val_accuracy: 0.8570\n",
      "Epoch 143/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3268 - accuracy: 0.8670 - val_loss: 0.3485 - val_accuracy: 0.8577\n",
      "Epoch 144/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3248 - accuracy: 0.8666 - val_loss: 0.3477 - val_accuracy: 0.8590\n",
      "Epoch 145/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3262 - accuracy: 0.8643 - val_loss: 0.3497 - val_accuracy: 0.8573\n",
      "Epoch 146/150\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3247 - accuracy: 0.8651 - val_loss: 0.3504 - val_accuracy: 0.8590\n",
      "Epoch 147/150\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3269 - accuracy: 0.8634 - val_loss: 0.3491 - val_accuracy: 0.8573\n",
      "Epoch 148/150\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3282 - accuracy: 0.8651 - val_loss: 0.3488 - val_accuracy: 0.8570\n",
      "Epoch 149/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3278 - accuracy: 0.8664 - val_loss: 0.3486 - val_accuracy: 0.8580\n",
      "Epoch 150/150\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3255 - accuracy: 0.8670 - val_loss: 0.3473 - val_accuracy: 0.8587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d2ccd6108>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5 # Threshold\n",
    "y_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics at 0.5 Threshold with 3 Hidden layer DNN model\n",
      "\n",
      "           3 Hidden Layer DNN\n",
      "accuracy             0.858667\n",
      "recall               0.452893\n",
      "precision            0.746594\n",
      "f1_score             0.563786\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics at 0.5 Threshold with 3 Hidden layer DNN model\\n')\n",
    "Test_Metrics_3_HiddenLayer_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n",
    "                   recall_score(y_test_array, y_test_preds), \n",
    "                   precision_score(y_test_array, y_test_preds),\n",
    "                   f1_score(y_test_array, y_test_preds)], columns=['3 Hidden Layer DNN'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Metrics_3_HiddenLayer_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2302,   93],\n",
       "       [ 331,  274]], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix with optimal Threshold on test set\n",
    "metrics.confusion_matrix(y_test_array, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not much improvement in accuracy, precision has improved, recall has gone down,overall accuracy is almost same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) With Batch normalisation after each hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Input layer to the model\n",
    "model.add(tf.keras.Input(shape=(13,))) # 13 Features\n",
    "\n",
    "# Batch Normalization Layer\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Layer_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 659\n",
      "Trainable params: 587\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/150\n",
      "7000/7000 [==============================] - 4s 590us/sample - loss: 0.6205 - accuracy: 0.6926 - val_loss: 0.5040 - val_accuracy: 0.8027\n",
      "Epoch 2/150\n",
      "7000/7000 [==============================] - 1s 132us/sample - loss: 0.4742 - accuracy: 0.8004 - val_loss: 0.4342 - val_accuracy: 0.8157\n",
      "Epoch 3/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.4329 - accuracy: 0.8131 - val_loss: 0.4035 - val_accuracy: 0.8257\n",
      "Epoch 4/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.4132 - accuracy: 0.8196 - val_loss: 0.3866 - val_accuracy: 0.8327\n",
      "Epoch 5/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3934 - accuracy: 0.8296 - val_loss: 0.3748 - val_accuracy: 0.8397\n",
      "Epoch 6/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3824 - accuracy: 0.8339 - val_loss: 0.3695 - val_accuracy: 0.8423\n",
      "Epoch 7/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3760 - accuracy: 0.8429 - val_loss: 0.3650 - val_accuracy: 0.8480\n",
      "Epoch 8/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3651 - accuracy: 0.8476 - val_loss: 0.3618 - val_accuracy: 0.8490\n",
      "Epoch 9/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3719 - accuracy: 0.8436 - val_loss: 0.3606 - val_accuracy: 0.8507\n",
      "Epoch 10/150\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3634 - accuracy: 0.8466 - val_loss: 0.3597 - val_accuracy: 0.8543\n",
      "Epoch 11/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3621 - accuracy: 0.8489 - val_loss: 0.3573 - val_accuracy: 0.8520\n",
      "Epoch 12/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3604 - accuracy: 0.8520 - val_loss: 0.3562 - val_accuracy: 0.8540\n",
      "Epoch 13/150\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3558 - accuracy: 0.8507 - val_loss: 0.3551 - val_accuracy: 0.8563\n",
      "Epoch 14/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3561 - accuracy: 0.8513 - val_loss: 0.3569 - val_accuracy: 0.8577\n",
      "Epoch 15/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3550 - accuracy: 0.8530 - val_loss: 0.3554 - val_accuracy: 0.8530\n",
      "Epoch 16/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3552 - accuracy: 0.8521 - val_loss: 0.3531 - val_accuracy: 0.8560\n",
      "Epoch 17/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3509 - accuracy: 0.8547 - val_loss: 0.3561 - val_accuracy: 0.8537\n",
      "Epoch 18/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3501 - accuracy: 0.8553 - val_loss: 0.3521 - val_accuracy: 0.8563\n",
      "Epoch 19/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3511 - accuracy: 0.8544 - val_loss: 0.3532 - val_accuracy: 0.8597\n",
      "Epoch 20/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3482 - accuracy: 0.8549 - val_loss: 0.3517 - val_accuracy: 0.8560\n",
      "Epoch 21/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3494 - accuracy: 0.8546 - val_loss: 0.3503 - val_accuracy: 0.8580\n",
      "Epoch 22/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3470 - accuracy: 0.8570 - val_loss: 0.3502 - val_accuracy: 0.8567\n",
      "Epoch 23/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3469 - accuracy: 0.8569 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 24/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3489 - accuracy: 0.8593 - val_loss: 0.3454 - val_accuracy: 0.8587\n",
      "Epoch 25/150\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3480 - accuracy: 0.8579 - val_loss: 0.3482 - val_accuracy: 0.8570\n",
      "Epoch 26/150\n",
      "7000/7000 [==============================] - 1s 133us/sample - loss: 0.3438 - accuracy: 0.8569 - val_loss: 0.3480 - val_accuracy: 0.8573\n",
      "Epoch 27/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3442 - accuracy: 0.8606 - val_loss: 0.3465 - val_accuracy: 0.8617\n",
      "Epoch 28/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3457 - accuracy: 0.8541 - val_loss: 0.3453 - val_accuracy: 0.8630\n",
      "Epoch 29/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3433 - accuracy: 0.8577 - val_loss: 0.3448 - val_accuracy: 0.8640\n",
      "Epoch 30/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3401 - accuracy: 0.8620 - val_loss: 0.3459 - val_accuracy: 0.8583\n",
      "Epoch 31/150\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3440 - accuracy: 0.8601 - val_loss: 0.3449 - val_accuracy: 0.8607\n",
      "Epoch 32/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3385 - accuracy: 0.8597 - val_loss: 0.3440 - val_accuracy: 0.8603\n",
      "Epoch 33/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3412 - accuracy: 0.8579 - val_loss: 0.3424 - val_accuracy: 0.8610\n",
      "Epoch 34/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3385 - accuracy: 0.8620 - val_loss: 0.3431 - val_accuracy: 0.8573\n",
      "Epoch 35/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3390 - accuracy: 0.8604 - val_loss: 0.3444 - val_accuracy: 0.8593\n",
      "Epoch 36/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3412 - accuracy: 0.8584 - val_loss: 0.3424 - val_accuracy: 0.8590\n",
      "Epoch 37/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3352 - accuracy: 0.8630 - val_loss: 0.3429 - val_accuracy: 0.8600\n",
      "Epoch 38/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3354 - accuracy: 0.8611 - val_loss: 0.3449 - val_accuracy: 0.8583\n",
      "Epoch 39/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3386 - accuracy: 0.8623 - val_loss: 0.3405 - val_accuracy: 0.8593\n",
      "Epoch 40/150\n",
      "7000/7000 [==============================] - 1s 144us/sample - loss: 0.3396 - accuracy: 0.8627 - val_loss: 0.3443 - val_accuracy: 0.8590\n",
      "Epoch 41/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3382 - accuracy: 0.8623 - val_loss: 0.3420 - val_accuracy: 0.8617\n",
      "Epoch 42/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3361 - accuracy: 0.8591 - val_loss: 0.3427 - val_accuracy: 0.8620\n",
      "Epoch 43/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3365 - accuracy: 0.8617 - val_loss: 0.3397 - val_accuracy: 0.8610\n",
      "Epoch 44/150\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3378 - accuracy: 0.8609 - val_loss: 0.3411 - val_accuracy: 0.8610\n",
      "Epoch 45/150\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3325 - accuracy: 0.8636 - val_loss: 0.3411 - val_accuracy: 0.8600\n",
      "Epoch 46/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3369 - accuracy: 0.8600 - val_loss: 0.3412 - val_accuracy: 0.8593\n",
      "Epoch 47/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3358 - accuracy: 0.8580 - val_loss: 0.3414 - val_accuracy: 0.8627\n",
      "Epoch 48/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3363 - accuracy: 0.8597 - val_loss: 0.3399 - val_accuracy: 0.8610\n",
      "Epoch 49/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3327 - accuracy: 0.8610 - val_loss: 0.3401 - val_accuracy: 0.8613\n",
      "Epoch 50/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3375 - accuracy: 0.8559 - val_loss: 0.3392 - val_accuracy: 0.8620\n",
      "Epoch 51/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3326 - accuracy: 0.8614 - val_loss: 0.3390 - val_accuracy: 0.8647\n",
      "Epoch 52/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3336 - accuracy: 0.8624 - val_loss: 0.3373 - val_accuracy: 0.8627\n",
      "Epoch 53/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3358 - accuracy: 0.8600 - val_loss: 0.3390 - val_accuracy: 0.8613\n",
      "Epoch 54/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3332 - accuracy: 0.8611 - val_loss: 0.3376 - val_accuracy: 0.8617\n",
      "Epoch 55/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3343 - accuracy: 0.8613 - val_loss: 0.3380 - val_accuracy: 0.8613\n",
      "Epoch 56/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3364 - accuracy: 0.8590 - val_loss: 0.3392 - val_accuracy: 0.8600\n",
      "Epoch 57/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3317 - accuracy: 0.8594 - val_loss: 0.3392 - val_accuracy: 0.8593\n",
      "Epoch 58/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3324 - accuracy: 0.8646 - val_loss: 0.3388 - val_accuracy: 0.8613\n",
      "Epoch 59/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3307 - accuracy: 0.8653 - val_loss: 0.3380 - val_accuracy: 0.8603\n",
      "Epoch 60/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3332 - accuracy: 0.8629 - val_loss: 0.3400 - val_accuracy: 0.8570\n",
      "Epoch 61/150\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3303 - accuracy: 0.8640 - val_loss: 0.3395 - val_accuracy: 0.8633\n",
      "Epoch 62/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3318 - accuracy: 0.8626 - val_loss: 0.3380 - val_accuracy: 0.8640\n",
      "Epoch 63/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3387 - val_accuracy: 0.8623\n",
      "Epoch 64/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3304 - accuracy: 0.8617 - val_loss: 0.3414 - val_accuracy: 0.8623\n",
      "Epoch 65/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3288 - accuracy: 0.8624 - val_loss: 0.3406 - val_accuracy: 0.8623\n",
      "Epoch 66/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3278 - accuracy: 0.8634 - val_loss: 0.3387 - val_accuracy: 0.8623\n",
      "Epoch 67/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3320 - accuracy: 0.8646 - val_loss: 0.3374 - val_accuracy: 0.8640\n",
      "Epoch 68/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3316 - accuracy: 0.8639 - val_loss: 0.3384 - val_accuracy: 0.8640\n",
      "Epoch 69/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3341 - accuracy: 0.8614 - val_loss: 0.3365 - val_accuracy: 0.8647\n",
      "Epoch 70/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3311 - accuracy: 0.8653 - val_loss: 0.3350 - val_accuracy: 0.8633\n",
      "Epoch 71/150\n",
      "7000/7000 [==============================] - 1s 144us/sample - loss: 0.3286 - accuracy: 0.8673 - val_loss: 0.3385 - val_accuracy: 0.8603\n",
      "Epoch 72/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3299 - accuracy: 0.8647 - val_loss: 0.3372 - val_accuracy: 0.8653\n",
      "Epoch 73/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3302 - accuracy: 0.8633 - val_loss: 0.3368 - val_accuracy: 0.8657\n",
      "Epoch 74/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3321 - accuracy: 0.8627 - val_loss: 0.3369 - val_accuracy: 0.8617\n",
      "Epoch 75/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3283 - accuracy: 0.8624 - val_loss: 0.3384 - val_accuracy: 0.8643\n",
      "Epoch 76/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3297 - accuracy: 0.8656 - val_loss: 0.3382 - val_accuracy: 0.8607\n",
      "Epoch 77/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3292 - accuracy: 0.8637 - val_loss: 0.3408 - val_accuracy: 0.8607\n",
      "Epoch 78/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3310 - accuracy: 0.8643 - val_loss: 0.3380 - val_accuracy: 0.8630\n",
      "Epoch 79/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3296 - accuracy: 0.8656 - val_loss: 0.3382 - val_accuracy: 0.8643\n",
      "Epoch 80/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3327 - accuracy: 0.8626 - val_loss: 0.3416 - val_accuracy: 0.8600\n",
      "Epoch 81/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3316 - accuracy: 0.8621 - val_loss: 0.3384 - val_accuracy: 0.8653\n",
      "Epoch 82/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3303 - accuracy: 0.8617 - val_loss: 0.3399 - val_accuracy: 0.8650\n",
      "Epoch 83/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3292 - accuracy: 0.8643 - val_loss: 0.3385 - val_accuracy: 0.8643\n",
      "Epoch 84/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3283 - accuracy: 0.8631 - val_loss: 0.3391 - val_accuracy: 0.8630\n",
      "Epoch 85/150\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3276 - accuracy: 0.8637 - val_loss: 0.3415 - val_accuracy: 0.8617\n",
      "Epoch 86/150\n",
      "7000/7000 [==============================] - 1s 133us/sample - loss: 0.3267 - accuracy: 0.8636 - val_loss: 0.3446 - val_accuracy: 0.8590\n",
      "Epoch 87/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3306 - accuracy: 0.8610 - val_loss: 0.3426 - val_accuracy: 0.8627\n",
      "Epoch 88/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3291 - accuracy: 0.8659 - val_loss: 0.3430 - val_accuracy: 0.8610\n",
      "Epoch 89/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3272 - accuracy: 0.8610 - val_loss: 0.3432 - val_accuracy: 0.8610\n",
      "Epoch 90/150\n",
      "7000/7000 [==============================] - 1s 132us/sample - loss: 0.3269 - accuracy: 0.8669 - val_loss: 0.3402 - val_accuracy: 0.8643\n",
      "Epoch 91/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3275 - accuracy: 0.8646 - val_loss: 0.3402 - val_accuracy: 0.8640\n",
      "Epoch 92/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3247 - accuracy: 0.8671 - val_loss: 0.3406 - val_accuracy: 0.8643\n",
      "Epoch 93/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3281 - accuracy: 0.8674 - val_loss: 0.3406 - val_accuracy: 0.8600\n",
      "Epoch 94/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3228 - accuracy: 0.8667 - val_loss: 0.3404 - val_accuracy: 0.8643\n",
      "Epoch 95/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3299 - accuracy: 0.8657 - val_loss: 0.3410 - val_accuracy: 0.8647\n",
      "Epoch 96/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3272 - accuracy: 0.8670 - val_loss: 0.3407 - val_accuracy: 0.8640\n",
      "Epoch 97/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3237 - accuracy: 0.8661 - val_loss: 0.3409 - val_accuracy: 0.8630\n",
      "Epoch 98/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3265 - accuracy: 0.8661 - val_loss: 0.3431 - val_accuracy: 0.8633\n",
      "Epoch 99/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3279 - accuracy: 0.8659 - val_loss: 0.3391 - val_accuracy: 0.8637\n",
      "Epoch 100/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3280 - accuracy: 0.8649 - val_loss: 0.3405 - val_accuracy: 0.8617\n",
      "Epoch 101/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3256 - accuracy: 0.8656 - val_loss: 0.3420 - val_accuracy: 0.8630\n",
      "Epoch 102/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3250 - accuracy: 0.8661 - val_loss: 0.3427 - val_accuracy: 0.8627\n",
      "Epoch 103/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3255 - accuracy: 0.8636 - val_loss: 0.3421 - val_accuracy: 0.8633\n",
      "Epoch 104/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3283 - accuracy: 0.8654 - val_loss: 0.3429 - val_accuracy: 0.8640\n",
      "Epoch 105/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3252 - accuracy: 0.8647 - val_loss: 0.3415 - val_accuracy: 0.8630\n",
      "Epoch 106/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3231 - accuracy: 0.8657 - val_loss: 0.3426 - val_accuracy: 0.8620\n",
      "Epoch 107/150\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3279 - accuracy: 0.8644 - val_loss: 0.3412 - val_accuracy: 0.8610\n",
      "Epoch 108/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3226 - accuracy: 0.8627 - val_loss: 0.3430 - val_accuracy: 0.8650\n",
      "Epoch 109/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3295 - accuracy: 0.8593 - val_loss: 0.3445 - val_accuracy: 0.8600\n",
      "Epoch 110/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3270 - accuracy: 0.8639 - val_loss: 0.3418 - val_accuracy: 0.8620\n",
      "Epoch 111/150\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.3251 - accuracy: 0.8680 - val_loss: 0.3445 - val_accuracy: 0.8607\n",
      "Epoch 112/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3263 - accuracy: 0.8664 - val_loss: 0.3424 - val_accuracy: 0.8617\n",
      "Epoch 113/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3235 - accuracy: 0.8663 - val_loss: 0.3442 - val_accuracy: 0.8597\n",
      "Epoch 114/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3232 - accuracy: 0.8647 - val_loss: 0.3436 - val_accuracy: 0.8610\n",
      "Epoch 115/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3283 - accuracy: 0.8640 - val_loss: 0.3440 - val_accuracy: 0.8623\n",
      "Epoch 116/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3264 - accuracy: 0.8653 - val_loss: 0.3449 - val_accuracy: 0.8600\n",
      "Epoch 117/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3281 - accuracy: 0.8636 - val_loss: 0.3455 - val_accuracy: 0.8583\n",
      "Epoch 118/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3246 - accuracy: 0.8636 - val_loss: 0.3444 - val_accuracy: 0.8600\n",
      "Epoch 119/150\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3232 - accuracy: 0.8666 - val_loss: 0.3463 - val_accuracy: 0.8620\n",
      "Epoch 120/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3231 - accuracy: 0.8670 - val_loss: 0.3448 - val_accuracy: 0.8570\n",
      "Epoch 121/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3221 - accuracy: 0.8651 - val_loss: 0.3421 - val_accuracy: 0.8603\n",
      "Epoch 122/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3248 - accuracy: 0.8647 - val_loss: 0.3416 - val_accuracy: 0.8600\n",
      "Epoch 123/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3280 - accuracy: 0.8641 - val_loss: 0.3429 - val_accuracy: 0.8610\n",
      "Epoch 124/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3222 - accuracy: 0.8650 - val_loss: 0.3463 - val_accuracy: 0.8613\n",
      "Epoch 125/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3245 - accuracy: 0.8633 - val_loss: 0.3466 - val_accuracy: 0.8627\n",
      "Epoch 126/150\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3239 - accuracy: 0.8657 - val_loss: 0.3461 - val_accuracy: 0.8607\n",
      "Epoch 127/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3255 - accuracy: 0.8631 - val_loss: 0.3452 - val_accuracy: 0.8653\n",
      "Epoch 128/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3223 - accuracy: 0.8663 - val_loss: 0.3449 - val_accuracy: 0.8627\n",
      "Epoch 129/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3212 - accuracy: 0.8653 - val_loss: 0.3447 - val_accuracy: 0.8637\n",
      "Epoch 130/150\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3212 - accuracy: 0.8680 - val_loss: 0.3436 - val_accuracy: 0.8610\n",
      "Epoch 131/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3247 - accuracy: 0.8646 - val_loss: 0.3430 - val_accuracy: 0.8627\n",
      "Epoch 132/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3244 - accuracy: 0.8654 - val_loss: 0.3450 - val_accuracy: 0.8610\n",
      "Epoch 133/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3224 - accuracy: 0.8676 - val_loss: 0.3472 - val_accuracy: 0.8623\n",
      "Epoch 134/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3248 - accuracy: 0.8659 - val_loss: 0.3446 - val_accuracy: 0.8617\n",
      "Epoch 135/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3259 - accuracy: 0.8677 - val_loss: 0.3445 - val_accuracy: 0.8630\n",
      "Epoch 136/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3233 - accuracy: 0.8649 - val_loss: 0.3432 - val_accuracy: 0.8613\n",
      "Epoch 137/150\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3246 - accuracy: 0.8660 - val_loss: 0.3471 - val_accuracy: 0.8610\n",
      "Epoch 138/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3230 - accuracy: 0.8664 - val_loss: 0.3457 - val_accuracy: 0.8620\n",
      "Epoch 139/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3226 - accuracy: 0.8656 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 140/150\n",
      "7000/7000 [==============================] - 4s 534us/sample - loss: 0.3221 - accuracy: 0.8649 - val_loss: 0.3425 - val_accuracy: 0.8623- accuracy\n",
      "Epoch 141/150\n",
      "7000/7000 [==============================] - 2s 302us/sample - loss: 0.3184 - accuracy: 0.8684 - val_loss: 0.3436 - val_accuracy: 0.8623\n",
      "Epoch 142/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3254 - accuracy: 0.8636 - val_loss: 0.3437 - val_accuracy: 0.8613\n",
      "Epoch 143/150\n",
      "7000/7000 [==============================] - 1s 133us/sample - loss: 0.3251 - accuracy: 0.8619 - val_loss: 0.3437 - val_accuracy: 0.8593\n",
      "Epoch 144/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3227 - accuracy: 0.8609 - val_loss: 0.3400 - val_accuracy: 0.8623\n",
      "Epoch 145/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3230 - accuracy: 0.8650 - val_loss: 0.3456 - val_accuracy: 0.8637\n",
      "Epoch 146/150\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3202 - accuracy: 0.8699 - val_loss: 0.3438 - val_accuracy: 0.8600\n",
      "Epoch 147/150\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3226 - accuracy: 0.8666 - val_loss: 0.3425 - val_accuracy: 0.8603\n",
      "Epoch 148/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3263 - accuracy: 0.8671 - val_loss: 0.3447 - val_accuracy: 0.8617\n",
      "Epoch 149/150\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3222 - accuracy: 0.8689 - val_loss: 0.3441 - val_accuracy: 0.8637\n",
      "Epoch 150/150\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3262 - accuracy: 0.8661 - val_loss: 0.3407 - val_accuracy: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d304a3a88>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5 # Threshold\n",
    "y_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics at 0.5 Threshold with  Batch Norm after each hidden layer DNN model\n",
      "\n",
      "           BatchNorm Hidden layers\n",
      "accuracy                  0.863667\n",
      "recall                    0.519008\n",
      "precision                 0.726852\n",
      "f1_score                  0.605593\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics at 0.5 Threshold with  Batch Norm after each hidden layer DNN model\\n')\n",
    "Test_Metrics_BatchNorm=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n",
    "                   recall_score(y_test_array, y_test_preds), \n",
    "                   precision_score(y_test_array, y_test_preds),\n",
    "                   f1_score(y_test_array, y_test_preds)], columns=['BatchNorm Hidden layers'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Metrics_BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2277,  118],\n",
       "       [ 291,  314]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix with optimal Threshold on test set\n",
    "metrics.confusion_matrix(y_test_array, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Accuracy, recall and F1 score has improved after adding Batch Normalisation after each hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Using Weight and Bias initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Input layer to the model\n",
    "model.add(tf.keras.Input(shape=(13,))) # 13 Features\n",
    "\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal', bias_initializer='Ones',activation='relu', name='Layer_1'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal',bias_initializer='Ones',activation='relu', name='Layer_2'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10,kernel_initializer='he_normal',bias_initializer='Ones', activation='relu', name='Layer_3'))\n",
    "# Batch Normalization Layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3236 - accuracy: 0.8650 - val_loss: 0.3442 - val_accuracy: 0.8550\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3197 - accuracy: 0.8726 - val_loss: 0.3462 - val_accuracy: 0.8553\n",
      "Epoch 3/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3243 - accuracy: 0.8650 - val_loss: 0.3483 - val_accuracy: 0.8563\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3178 - accuracy: 0.8663 - val_loss: 0.3461 - val_accuracy: 0.8560\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 1s 133us/sample - loss: 0.3202 - accuracy: 0.8667 - val_loss: 0.3496 - val_accuracy: 0.8560\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3194 - accuracy: 0.8671 - val_loss: 0.3445 - val_accuracy: 0.8563\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 1s 133us/sample - loss: 0.3181 - accuracy: 0.8657 - val_loss: 0.3465 - val_accuracy: 0.8550\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3213 - accuracy: 0.8696 - val_loss: 0.3465 - val_accuracy: 0.8550\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3210 - accuracy: 0.8671 - val_loss: 0.3456 - val_accuracy: 0.8543\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3244 - accuracy: 0.8669 - val_loss: 0.3450 - val_accuracy: 0.8553\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3249 - accuracy: 0.8681 - val_loss: 0.3451 - val_accuracy: 0.8590\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3203 - accuracy: 0.8673 - val_loss: 0.3447 - val_accuracy: 0.8607\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3212 - accuracy: 0.8687 - val_loss: 0.3442 - val_accuracy: 0.8570\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3238 - accuracy: 0.8653 - val_loss: 0.3426 - val_accuracy: 0.8560\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3230 - accuracy: 0.8690 - val_loss: 0.3461 - val_accuracy: 0.8553\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3200 - accuracy: 0.8644 - val_loss: 0.3437 - val_accuracy: 0.8580\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3203 - accuracy: 0.8706 - val_loss: 0.3459 - val_accuracy: 0.8537\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3217 - accuracy: 0.8639 - val_loss: 0.3465 - val_accuracy: 0.8577\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3224 - accuracy: 0.8651 - val_loss: 0.3450 - val_accuracy: 0.8557\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3192 - accuracy: 0.8667 - val_loss: 0.3448 - val_accuracy: 0.8573\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3182 - accuracy: 0.8704 - val_loss: 0.3507 - val_accuracy: 0.8520\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3213 - accuracy: 0.8661 - val_loss: 0.3468 - val_accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3177 - accuracy: 0.8716 - val_loss: 0.3446 - val_accuracy: 0.8553\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 1s 129us/sample - loss: 0.3194 - accuracy: 0.8676 - val_loss: 0.3443 - val_accuracy: 0.8577\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3231 - accuracy: 0.8689 - val_loss: 0.3444 - val_accuracy: 0.8573\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3222 - accuracy: 0.8700 - val_loss: 0.3447 - val_accuracy: 0.8550\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3215 - accuracy: 0.8684 - val_loss: 0.3451 - val_accuracy: 0.8583\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3204 - accuracy: 0.8629 - val_loss: 0.3440 - val_accuracy: 0.8560\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3214 - accuracy: 0.8656 - val_loss: 0.3448 - val_accuracy: 0.8547\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3214 - accuracy: 0.8654 - val_loss: 0.3461 - val_accuracy: 0.8560\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3221 - accuracy: 0.8696 - val_loss: 0.3455 - val_accuracy: 0.8567\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 1s 132us/sample - loss: 0.3199 - accuracy: 0.8689 - val_loss: 0.3433 - val_accuracy: 0.8553\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3177 - accuracy: 0.8713 - val_loss: 0.3454 - val_accuracy: 0.8543\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3187 - accuracy: 0.8673 - val_loss: 0.3449 - val_accuracy: 0.8563\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.3155 - accuracy: 0.8699 - val_loss: 0.3472 - val_accuracy: 0.8557\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3204 - accuracy: 0.8701 - val_loss: 0.3438 - val_accuracy: 0.8583\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3211 - accuracy: 0.8683 - val_loss: 0.3452 - val_accuracy: 0.8553\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3211 - accuracy: 0.8649 - val_loss: 0.3465 - val_accuracy: 0.8557\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3149 - accuracy: 0.8709 - val_loss: 0.3442 - val_accuracy: 0.8563\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3228 - accuracy: 0.8653 - val_loss: 0.3436 - val_accuracy: 0.8583\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3179 - accuracy: 0.8701 - val_loss: 0.3443 - val_accuracy: 0.8580\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3163 - accuracy: 0.8659 - val_loss: 0.3443 - val_accuracy: 0.8550\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3185 - accuracy: 0.8649 - val_loss: 0.3439 - val_accuracy: 0.8590\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3228 - accuracy: 0.8681 - val_loss: 0.3440 - val_accuracy: 0.8577\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.3225 - accuracy: 0.8647 - val_loss: 0.3428 - val_accuracy: 0.8607\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3216 - accuracy: 0.8649 - val_loss: 0.3434 - val_accuracy: 0.8580\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3198 - accuracy: 0.8666 - val_loss: 0.3446 - val_accuracy: 0.8567\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3209 - accuracy: 0.8656 - val_loss: 0.3457 - val_accuracy: 0.8593\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3186 - accuracy: 0.8659 - val_loss: 0.3452 - val_accuracy: 0.8567\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3204 - accuracy: 0.8700 - val_loss: 0.3451 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d41c49108>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=50,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5 # Threshold\n",
    "y_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics at 0.5 Threshold withv Weight and Bias initialization &  Batch Norm after each hidden layer DNN model\n",
      "\n",
      "           Weight Initialize\n",
      "accuracy            0.856000\n",
      "recall              0.447934\n",
      "precision           0.734417\n",
      "f1_score            0.556468\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics at 0.5 Threshold withv Weight and Bias initialization &  Batch Norm after each hidden layer DNN model\\n')\n",
    "Test_Metrics_Weight_Init=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n",
    "                   recall_score(y_test_array, y_test_preds), \n",
    "                   precision_score(y_test_array, y_test_preds),\n",
    "                   f1_score(y_test_array, y_test_preds)], columns=['Weight Initialize'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Metrics_Weight_Init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2297,   98],\n",
       "       [ 334,  271]], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix with optimal Threshold on test set\n",
    "metrics.confusion_matrix(y_test_array, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy has dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Apply Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Input layer to the model\n",
    "model.add(tf.keras.Input(shape=(13,))) # 13 Features\n",
    "\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n",
    "\n",
    "\n",
    "# Dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Layer_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 515\n",
      "Trainable params: 515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 2s 300us/sample - loss: 0.6138 - accuracy: 0.7003 - val_loss: 0.4826 - val_accuracy: 0.7983\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 1s 104us/sample - loss: 0.5083 - accuracy: 0.7936 - val_loss: 0.4481 - val_accuracy: 0.7983\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.4786 - accuracy: 0.7967 - val_loss: 0.4343 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.4637 - accuracy: 0.8004 - val_loss: 0.4191 - val_accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 1s 104us/sample - loss: 0.4467 - accuracy: 0.8049 - val_loss: 0.4059 - val_accuracy: 0.8180\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 1s 103us/sample - loss: 0.4366 - accuracy: 0.8103 - val_loss: 0.3893 - val_accuracy: 0.8240\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 1s 105us/sample - loss: 0.4136 - accuracy: 0.8231 - val_loss: 0.3726 - val_accuracy: 0.8383\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.4119 - accuracy: 0.8254 - val_loss: 0.3695 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 1s 104us/sample - loss: 0.4034 - accuracy: 0.8293 - val_loss: 0.3642 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.3964 - accuracy: 0.8329 - val_loss: 0.3631 - val_accuracy: 0.8490\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.3893 - accuracy: 0.8364 - val_loss: 0.3599 - val_accuracy: 0.8513\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3855 - accuracy: 0.8369 - val_loss: 0.3599 - val_accuracy: 0.8520\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3865 - accuracy: 0.8344 - val_loss: 0.3581 - val_accuracy: 0.8530\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3842 - accuracy: 0.8409 - val_loss: 0.3563 - val_accuracy: 0.8557\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3787 - accuracy: 0.8393 - val_loss: 0.3569 - val_accuracy: 0.8553\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3791 - accuracy: 0.8421 - val_loss: 0.3544 - val_accuracy: 0.8560\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 1s 103us/sample - loss: 0.3750 - accuracy: 0.8429 - val_loss: 0.3535 - val_accuracy: 0.8597\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3759 - accuracy: 0.8437 - val_loss: 0.3544 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3711 - accuracy: 0.8476 - val_loss: 0.3543 - val_accuracy: 0.8557\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3740 - accuracy: 0.8441 - val_loss: 0.3514 - val_accuracy: 0.8597\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3747 - accuracy: 0.8463 - val_loss: 0.3524 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3641 - accuracy: 0.8523 - val_loss: 0.3503 - val_accuracy: 0.8597\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3696 - accuracy: 0.8473 - val_loss: 0.3500 - val_accuracy: 0.8570\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3703 - accuracy: 0.8454 - val_loss: 0.3490 - val_accuracy: 0.8593\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 1s 104us/sample - loss: 0.3669 - accuracy: 0.8473 - val_loss: 0.3500 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3669 - accuracy: 0.8494 - val_loss: 0.3497 - val_accuracy: 0.8593\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3666 - accuracy: 0.8471 - val_loss: 0.3498 - val_accuracy: 0.8597\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3659 - accuracy: 0.8451 - val_loss: 0.3490 - val_accuracy: 0.8583\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3671 - accuracy: 0.8479 - val_loss: 0.3492 - val_accuracy: 0.8587\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3635 - accuracy: 0.8509 - val_loss: 0.3465 - val_accuracy: 0.8593\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3642 - accuracy: 0.8481 - val_loss: 0.3463 - val_accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 1s 100us/sample - loss: 0.3592 - accuracy: 0.8497 - val_loss: 0.3453 - val_accuracy: 0.8593\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3605 - accuracy: 0.8533 - val_loss: 0.3468 - val_accuracy: 0.8590\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 1s 102us/sample - loss: 0.3619 - accuracy: 0.8524 - val_loss: 0.3482 - val_accuracy: 0.8587\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3611 - accuracy: 0.8519 - val_loss: 0.3449 - val_accuracy: 0.8627\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 1s 104us/sample - loss: 0.3610 - accuracy: 0.8516 - val_loss: 0.3452 - val_accuracy: 0.8597\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3627 - accuracy: 0.8517 - val_loss: 0.3449 - val_accuracy: 0.8603\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3583 - accuracy: 0.8527 - val_loss: 0.3442 - val_accuracy: 0.8603\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3596 - accuracy: 0.8557 - val_loss: 0.3459 - val_accuracy: 0.8613\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3567 - accuracy: 0.8560 - val_loss: 0.3432 - val_accuracy: 0.8597\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3564 - accuracy: 0.8557 - val_loss: 0.3439 - val_accuracy: 0.8597\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3592 - accuracy: 0.8511 - val_loss: 0.3416 - val_accuracy: 0.8650\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3556 - accuracy: 0.8541 - val_loss: 0.3420 - val_accuracy: 0.8597\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3556 - accuracy: 0.8590 - val_loss: 0.3417 - val_accuracy: 0.8617\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3589 - accuracy: 0.8561 - val_loss: 0.3425 - val_accuracy: 0.8610\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3536 - accuracy: 0.8553 - val_loss: 0.3416 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3564 - accuracy: 0.8551 - val_loss: 0.3407 - val_accuracy: 0.8633\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3531 - accuracy: 0.8569 - val_loss: 0.3418 - val_accuracy: 0.8620\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3587 - accuracy: 0.8534 - val_loss: 0.3413 - val_accuracy: 0.8620\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3556 - accuracy: 0.8549 - val_loss: 0.3428 - val_accuracy: 0.8607\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3582 - accuracy: 0.8580 - val_loss: 0.3407 - val_accuracy: 0.8617\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3518 - accuracy: 0.8554 - val_loss: 0.3410 - val_accuracy: 0.8633\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3535 - accuracy: 0.8543 - val_loss: 0.3404 - val_accuracy: 0.8623\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3537 - accuracy: 0.8554 - val_loss: 0.3409 - val_accuracy: 0.8613\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3547 - accuracy: 0.8584 - val_loss: 0.3421 - val_accuracy: 0.8640\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3557 - accuracy: 0.8559 - val_loss: 0.3404 - val_accuracy: 0.8613\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3506 - accuracy: 0.8537 - val_loss: 0.3400 - val_accuracy: 0.8623\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3508 - accuracy: 0.8587 - val_loss: 0.3416 - val_accuracy: 0.8637\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3535 - accuracy: 0.8559 - val_loss: 0.3416 - val_accuracy: 0.8623\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3546 - accuracy: 0.8549 - val_loss: 0.3429 - val_accuracy: 0.8647\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3510 - accuracy: 0.8569 - val_loss: 0.3409 - val_accuracy: 0.8617\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3511 - accuracy: 0.8553 - val_loss: 0.3412 - val_accuracy: 0.8617\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3525 - accuracy: 0.8556 - val_loss: 0.3404 - val_accuracy: 0.8613\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3489 - accuracy: 0.8570 - val_loss: 0.3410 - val_accuracy: 0.8637\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3508 - accuracy: 0.8563 - val_loss: 0.3406 - val_accuracy: 0.8593\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3527 - accuracy: 0.8576 - val_loss: 0.3432 - val_accuracy: 0.8643\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3546 - accuracy: 0.8526 - val_loss: 0.3405 - val_accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3509 - accuracy: 0.8576 - val_loss: 0.3413 - val_accuracy: 0.8613\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3533 - accuracy: 0.8553 - val_loss: 0.3414 - val_accuracy: 0.8600\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3614 - accuracy: 0.8523 - val_loss: 0.3405 - val_accuracy: 0.8597\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3492 - accuracy: 0.8566 - val_loss: 0.3388 - val_accuracy: 0.8617\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3553 - accuracy: 0.8554 - val_loss: 0.3400 - val_accuracy: 0.8647\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3538 - accuracy: 0.8561 - val_loss: 0.3394 - val_accuracy: 0.8613\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3547 - accuracy: 0.8566 - val_loss: 0.3402 - val_accuracy: 0.8627\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3542 - accuracy: 0.8556 - val_loss: 0.3401 - val_accuracy: 0.8633\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3501 - accuracy: 0.8610 - val_loss: 0.3413 - val_accuracy: 0.8640\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3537 - accuracy: 0.8567 - val_loss: 0.3388 - val_accuracy: 0.8593\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3533 - accuracy: 0.8564 - val_loss: 0.3422 - val_accuracy: 0.8627\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3558 - accuracy: 0.8564 - val_loss: 0.3399 - val_accuracy: 0.8620\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3514 - accuracy: 0.8583 - val_loss: 0.3398 - val_accuracy: 0.8623\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3501 - accuracy: 0.8570 - val_loss: 0.3415 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3465 - accuracy: 0.8576 - val_loss: 0.3413 - val_accuracy: 0.8647\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3512 - accuracy: 0.8577 - val_loss: 0.3392 - val_accuracy: 0.8623\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3501 - accuracy: 0.8579 - val_loss: 0.3395 - val_accuracy: 0.8657\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3509 - accuracy: 0.8579 - val_loss: 0.3382 - val_accuracy: 0.8633\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3539 - accuracy: 0.8553 - val_loss: 0.3389 - val_accuracy: 0.8633\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3478 - accuracy: 0.8580 - val_loss: 0.3383 - val_accuracy: 0.8620\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3450 - accuracy: 0.8606 - val_loss: 0.3398 - val_accuracy: 0.8637\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3535 - accuracy: 0.8579 - val_loss: 0.3410 - val_accuracy: 0.8643\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3529 - accuracy: 0.8551 - val_loss: 0.3383 - val_accuracy: 0.8653\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3473 - accuracy: 0.8576 - val_loss: 0.3385 - val_accuracy: 0.8613\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3505 - accuracy: 0.8547 - val_loss: 0.3387 - val_accuracy: 0.8653\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3518 - accuracy: 0.8573 - val_loss: 0.3396 - val_accuracy: 0.8637\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3520 - accuracy: 0.8566 - val_loss: 0.3391 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3515 - accuracy: 0.8557 - val_loss: 0.3413 - val_accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3461 - accuracy: 0.8577 - val_loss: 0.3387 - val_accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 1s 113us/sample - loss: 0.3516 - accuracy: 0.8550 - val_loss: 0.3411 - val_accuracy: 0.8643\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3508 - accuracy: 0.8577 - val_loss: 0.3382 - val_accuracy: 0.8657\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 1s 112us/sample - loss: 0.3495 - accuracy: 0.8573 - val_loss: 0.3387 - val_accuracy: 0.8630\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3517 - accuracy: 0.8596 - val_loss: 0.3373 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d448779c8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=100,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5 # Threshold\n",
    "y_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics at 0.5 Threshold Dropout DNN model\n",
      "\n",
      "            DropOut\n",
      "accuracy   0.863333\n",
      "recall     0.444628\n",
      "precision  0.784257\n",
      "f1_score   0.567511\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics at 0.5 Threshold Dropout DNN model\\n')\n",
    "Test_Metrics_DropOut=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n",
    "                   recall_score(y_test_array, y_test_preds), \n",
    "                   precision_score(y_test_array, y_test_preds),\n",
    "                   f1_score(y_test_array, y_test_preds)], columns=['DropOut'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Metrics_DropOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2321,   74],\n",
       "       [ 336,  269]], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix with optimal Threshold on test set\n",
    "metrics.confusion_matrix(y_test_array, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still Accuracy has not improved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic DNN</th>\n",
       "      <th>3 Hidden Layer DNN</th>\n",
       "      <th>BatchNorm Hidden layers</th>\n",
       "      <th>Weight Initialize</th>\n",
       "      <th>DropOut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.863667</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.452893</td>\n",
       "      <td>0.519008</td>\n",
       "      <td>0.447934</td>\n",
       "      <td>0.444628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.746594</td>\n",
       "      <td>0.726852</td>\n",
       "      <td>0.734417</td>\n",
       "      <td>0.784257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.563786</td>\n",
       "      <td>0.605593</td>\n",
       "      <td>0.556468</td>\n",
       "      <td>0.567511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Basic DNN  3 Hidden Layer DNN  BatchNorm Hidden layers  \\\n",
       "accuracy    0.860000            0.858667                 0.863667   \n",
       "recall      0.495868            0.452893                 0.519008   \n",
       "precision   0.722892            0.746594                 0.726852   \n",
       "f1_score    0.588235            0.563786                 0.605593   \n",
       "\n",
       "           Weight Initialize   DropOut  \n",
       "accuracy            0.856000  0.863333  \n",
       "recall              0.447934  0.444628  \n",
       "precision           0.734417  0.784257  \n",
       "f1_score            0.556468  0.567511  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Comparison_df=Test_Metrics_Basic_DNN\n",
    "Model_Comparison_df['3 Hidden Layer DNN']=Test_Metrics_3_HiddenLayer_DNN['3 Hidden Layer DNN']\n",
    "Model_Comparison_df['BatchNorm Hidden layers']=Test_Metrics_BatchNorm['BatchNorm Hidden layers']\n",
    "Model_Comparison_df['Weight Initialize']=Test_Metrics_Weight_Init['Weight Initialize']\n",
    "Model_Comparison_df['DropOut']=Test_Metrics_DropOut['DropOut']\n",
    "#Model_Comparison_df['Naive Bayes']=Naive_Bayes_metrics['Naive Bayes']\n",
    "Model_Comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Among the models tried above Model with bath normalization after each hidden layer gives best Accurracy and F1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
